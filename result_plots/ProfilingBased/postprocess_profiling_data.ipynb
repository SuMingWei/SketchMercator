{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19d8f030-f632-483e-aff3-584bb9636df6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f29f21-3535-4f3c-a06f-bd17bec0c30c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Split profile to per pcap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe071780-bb7a-438e-8afd-ecd0206dd437",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: ./results/profiler_caida_interval/naive/hll_level_1_result.json\n",
      "Input: ./results/profiler_caida_interval/naive/cm_level_1_result.json\n",
      "Input: ./results/profiler_caida_interval/naive/mrac_level_8_result.json\n",
      "Input: ./results/profiler_caida_interval/naive/lc_level_1_result.json\n",
      "Input: ./results/profiler_caida_interval/naive/mrb_level_8_result.json\n",
      "Input: ./results/profiler_caida_interval/naive/ll_level_1_result.json\n",
      "Input: ./results/profiler_caida_interval/naive/cs_level_1_result.json\n"
     ]
    }
   ],
   "source": [
    "datasets = ['equinix-nyc.dirA.20180517-130100.UTC.anon.pcap/', 'equinix-nyc.dirA.20180517-130500.UTC.anon.pcap/', 'equinix-nyc.dirA.20180517-131000.UTC.anon.pcap/', \n",
    "            'equinix-nyc.dirA.20180517-133000.UTC.anon.pcap/', 'equinix-nyc.dirA.20180517-140000.UTC.anon.pcap/', \n",
    "            'equinix-nyc.dirA.20180621-130100.UTC.anon.pcap/', 'equinix-nyc.dirA.20180621-130500.UTC.anon.pcap/', 'equinix-nyc.dirA.20180621-131000.UTC.anon.pcap/', \n",
    "            'equinix-nyc.dirA.20180621-133000.UTC.anon.pcap/', 'equinix-nyc.dirA.20180621-140000.UTC.anon.pcap/',\n",
    "            'equinix-nyc.dirA.20180816-130100.UTC.anon.pcap/', 'equinix-nyc.dirA.20180816-130500.UTC.anon.pcap/', 'equinix-nyc.dirA.20180816-131000.UTC.anon.pcap/', \n",
    "            'equinix-nyc.dirA.20180816-133000.UTC.anon.pcap/', 'equinix-nyc.dirA.20180816-140000.UTC.anon.pcap/', \n",
    "            'equinix-nyc.dirA.20181018-130100.UTC.anon.pcap/', 'equinix-nyc.dirA.20181018-130500.UTC.anon.pcap/', 'equinix-nyc.dirA.20181018-131000.UTC.anon.pcap/', \n",
    "            'equinix-nyc.dirA.20181018-133000.UTC.anon.pcap/', 'equinix-nyc.dirA.20181018-140000.UTC.anon.pcap/', \n",
    "            'equinix-nyc.dirA.20181115-130100.UTC.anon.pcap/', 'equinix-nyc.dirA.20181115-130500.UTC.anon.pcap/', 'equinix-nyc.dirA.20181115-131000.UTC.anon.pcap/', \n",
    "            'equinix-nyc.dirA.20181115-133000.UTC.anon.pcap/', 'equinix-nyc.dirA.20181115-140000.UTC.anon.pcap/', \n",
    "            'equinix-nyc.dirA.20181220-130100.UTC.anon.pcap/', 'equinix-nyc.dirA.20181220-130500.UTC.anon.pcap/', 'equinix-nyc.dirA.20181220-131000.UTC.anon.pcap/', \n",
    "            'equinix-nyc.dirA.20181220-133000.UTC.anon.pcap/', 'equinix-nyc.dirA.20181220-140000.UTC.anon.pcap/', ]\n",
    "\n",
    "input_dir = './results/profiler_caida_interval/naive/'\n",
    "output_dir = './results/profiler_caida_interval/output/'\n",
    "\n",
    "# iterate each file under input_dir\n",
    "for d in os.listdir(input_dir):\n",
    "    filename = input_dir + d\n",
    "    \n",
    "    if os.path.isfile(filename):\n",
    "        with open(filename) as f:\n",
    "            js = json.loads(f.read())\n",
    "            print('Input: ' + filename)\n",
    "            \n",
    "            # split profile by 1 single pcap\n",
    "            for i, date in enumerate(datasets):\n",
    "                tmp = date.split('.')[2]\n",
    "                path = output_dir + tmp + '/'\n",
    "                # print(path)\n",
    "                if not os.path.exists(path):\n",
    "                    os.makedirs(path)\n",
    "                \n",
    "                # key: metric, row (number), width (byte)\n",
    "                ret = {}\n",
    "                for m in js:\n",
    "                    ret[m] = {}\n",
    "                    for r in js[m]:\n",
    "                        ret[m][r] = {}\n",
    "                        for w in js[m][r]:\n",
    "                            ret[m][r][w] = []\n",
    "                            ret[m][r][w].append(js[m][r][w][i*2])\n",
    "                            ret[m][r][w].append(js[m][r][w][i*2+1])\n",
    "                # print(ret)\n",
    "                path = f'{path}{d}'\n",
    "                # print('Output: ' + path)\n",
    "                with open(path, 'w') as out:\n",
    "                    json.dump(ret, out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce37adb6-cea6-4b71-bdc0-70e6c63cb72b",
   "metadata": {},
   "source": [
    "## Split data for different number of pcaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8606831b-8743-4d36-be9c-2319def439ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: ./results/profiler_caida_num_of_pcaps/naive/hll_level_1_result.json\n",
      "Input: ./results/profiler_caida_num_of_pcaps/naive/cm_level_1_result.json\n",
      "Input: ./results/profiler_caida_num_of_pcaps/naive/mrac_level_8_result.json\n",
      "Input: ./results/profiler_caida_num_of_pcaps/naive/univmon_level_16_result.json\n",
      "Input: ./results/profiler_caida_num_of_pcaps/naive/lc_level_1_result.json\n",
      "Input: ./results/profiler_caida_num_of_pcaps/naive/mrb_level_8_result.json\n",
      "Input: ./results/profiler_caida_num_of_pcaps/naive/ll_level_1_result.json\n",
      "Input: ./results/profiler_caida_num_of_pcaps/naive/cs_level_1_result.json\n"
     ]
    }
   ],
   "source": [
    "input_dir = './results/profiler_caida_num_of_pcaps/naive/'\n",
    "output_dir = './results/profiler_caida_num_of_pcaps/output/'\n",
    "\n",
    "nums_of_pcap = [1, 3, 5, 7, 9, ] # 11\n",
    "pcap_total_time = 60 # 60 sec\n",
    "epoch = 30 # 30 sec\n",
    "cnt_of_epoch = int(pcap_total_time / epoch)\n",
    "\n",
    "# iterate each file under input_dir\n",
    "for d in os.listdir(input_dir):\n",
    "    filename = input_dir + d\n",
    "    \n",
    "    if os.path.isfile(filename):\n",
    "        with open(filename) as f:\n",
    "            js = json.loads(f.read())\n",
    "            print('Input: ' + filename)\n",
    "\n",
    "            for num in nums_of_pcap:\n",
    "                # print(num)\n",
    "                # key: metric, row (number), width (byte)\n",
    "                ret = {}\n",
    "                for m in js:\n",
    "                    ret[m] = {}\n",
    "                    for r in js[m]:\n",
    "                        ret[m][r] = {}\n",
    "                        for w in js[m][r]:\n",
    "                            ret[m][r][w] = js[m][r][w][0:num*cnt_of_epoch]\n",
    "                # print(ret)\n",
    "                path = output_dir + f'pcap_{num}/'\n",
    "                if not os.path.exists(path):\n",
    "                    os.makedirs(path)\n",
    "                # print('Output: ' + path + d)\n",
    "                with open(path + d, 'w') as out:\n",
    "                    json.dump(ret, out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "526aab7e-11bf-451c-b70b-cda412a5e539",
   "metadata": {},
   "source": [
    "## Split data for different number of pcaps with specific dates (index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "464faed1-43e7-4b8a-9b82-e28581f04cd4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_dir = './results/profiler_caida_num_of_pcaps/naive/'\n",
    "output_dir = './results/profiler_caida_num_of_pcaps/output2/'\n",
    "\n",
    "indexes = [[0], [0, 6, 7], [0, 1, 2, 6, 7], \n",
    "           [0, 1, 2, 3, 6, 7, 8],\n",
    "           [0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
    "           [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10],]\n",
    "\n",
    "\n",
    "nums_of_pcap = [1, 3, 5, 7, 9, 11]\n",
    "pcap_total_time = 60 # 60 sec\n",
    "epoch = 30 # 30 sec\n",
    "cnt_of_epoch = int(pcap_total_time / epoch)\n",
    "\n",
    "# iterate each file under input_dir\n",
    "for d in os.listdir(input_dir):\n",
    "    filename = input_dir + d\n",
    "    \n",
    "    if os.path.isfile(filename):\n",
    "        with open(filename) as f:\n",
    "            js = json.loads(f.read())\n",
    "            print('Input: ' + filename)\n",
    "\n",
    "            for num, idx_list in zip(nums_of_pcap, indexes):\n",
    "                # print(num)\n",
    "                # key: metric, row (number), width (byte)\n",
    "                ret = {}\n",
    "                for m in js:\n",
    "                    ret[m] = {}\n",
    "                    for r in js[m]:\n",
    "                        ret[m][r] = {}\n",
    "                        for w in js[m][r]:\n",
    "                            ll = []\n",
    "                            for idx in idx_list:\n",
    "                                ll.append(js[m][r][w][idx*2])\n",
    "                                ll.append(js[m][r][w][idx*2 + 1])\n",
    "                            ret[m][r][w] = ll\n",
    "                # print(ret)\n",
    "                path = output_dir + f'pcap_{num}/'\n",
    "                if not os.path.exists(path):\n",
    "                    os.makedirs(path)\n",
    "                print('Output: ' + path + d)\n",
    "                with open(path + d, 'w') as out:\n",
    "                    json.dump(ret, out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef398b5-af7a-4f35-9005-7479d739ae27",
   "metadata": {},
   "source": [
    "## Split data for different number of pcaps with multiple random runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "048f8a17-c7c6-485e-be52-0614a7054e39",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: ./results/profiler_caida_num_of_pcaps/naive/hll_level_1_result.json\n",
      "Input: ./results/profiler_caida_num_of_pcaps/naive/cm_level_1_result.json\n",
      "Input: ./results/profiler_caida_num_of_pcaps/naive/mrac_level_8_result.json\n",
      "Input: ./results/profiler_caida_num_of_pcaps/naive/lc_level_1_result.json\n",
      "Input: ./results/profiler_caida_num_of_pcaps/naive/mrb_level_8_result.json\n",
      "Input: ./results/profiler_caida_num_of_pcaps/naive/ll_level_1_result.json\n",
      "Input: ./results/profiler_caida_num_of_pcaps/naive/cs_level_1_result.json\n"
     ]
    }
   ],
   "source": [
    "input_dir = './results/profiler_caida_num_of_pcaps/naive/'\n",
    "output_dir_base = './results/profiler_caida_num_of_pcaps/'\n",
    "\n",
    "# indexes = [[0], [0, 6, 7], [0, 1, 2, 6, 7], \n",
    "#            [0, 1, 2, 3, 6, 7, 8],\n",
    "#            [0, 1, 2, 3, 4, 5, 6, 7, 8],\n",
    "#            [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10],]\n",
    "\n",
    "nums_of_pcap = [1, 3, 5, 7, 9]\n",
    "nums_of_random_runs = 5\n",
    "total_pcaps_num = 9\n",
    "\n",
    "\n",
    "pcap_total_time = 60 # 60 sec\n",
    "epoch = 30 # 30 sec\n",
    "cnt_of_epoch = int(pcap_total_time / epoch)\n",
    "\n",
    "# iterate each file under input_dir\n",
    "for d in os.listdir(input_dir):\n",
    "    filename = input_dir + d\n",
    "    \n",
    "    if os.path.isfile(filename):\n",
    "        with open(filename) as f:\n",
    "            js = json.loads(f.read())\n",
    "            print('Input: ' + filename)\n",
    "            random.seed(0)\n",
    "            \n",
    "            for runs in range(nums_of_random_runs):\n",
    "                # print(f'runs: {runs}')\n",
    "                for num in nums_of_pcap:\n",
    "                    idx_list = random.sample(range(total_pcaps_num), num)\n",
    "                    # print(num, idx_list)\n",
    "                    \n",
    "                    ret = {}\n",
    "                    for m in js:\n",
    "                        ret[m] = {}\n",
    "                        for r in js[m]:\n",
    "                            ret[m][r] = {}\n",
    "                            for w in js[m][r]:\n",
    "                                ll = []\n",
    "                                for idx in idx_list:\n",
    "                                    ll.append(js[m][r][w][idx*2])\n",
    "                                    ll.append(js[m][r][w][idx*2 + 1])\n",
    "                                ret[m][r][w] = ll\n",
    "                    # print(ret)\n",
    "                    output_dir = output_dir_base + f'runs_{runs}/'\n",
    "                    path = output_dir + f'pcap_{num}/'\n",
    "                    if not os.path.exists(path):\n",
    "                        os.makedirs(path)\n",
    "                    # print('Output: ' + path + d)\n",
    "                    with open(path + d, 'w') as out:\n",
    "                        json.dump(ret, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcfe070b-177e-4112-8a2c-60d38a53130c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "981e7199-6006-4c46-bcf6-6d58acf87fb2",
   "metadata": {},
   "source": [
    "---\n",
    "# OLD (obselete)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b54277-8e19-477e-b43b-a9bf00ac8d41",
   "metadata": {},
   "source": [
    "## Split profile to per pcap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "70a3c4f5-3390-45b4-b1ba-5cd60aa9e6bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: ./results/profiler/hll_level_1_result.json\n",
      "Input: ./results/profiler/cm_level_1_result.json\n",
      "Input: ./results/profiler/mrac_level_8_result.json\n",
      "Input: ./results/profiler/univmon_level_16_result.json\n",
      "Input: ./results/profiler/lc_level_1_result.json\n",
      "Input: ./results/profiler/mrb_level_8_result.json\n",
      "Input: ./results/profiler/ll_level_1_result.json\n",
      "Input: ./results/profiler/cs_level_1_result.json\n"
     ]
    }
   ],
   "source": [
    "datasets = ['equinix-nyc.dirA.20180517-130900.UTC.anon.pcap/', 'equinix-nyc.dirA.20180517-131000.UTC.anon.pcap/', 'equinix-nyc.dirA.20180517-131100.UTC.anon.pcap/', \n",
    "           'equinix-nyc.dirA.20180621-130900.UTC.anon.pcap/', 'equinix-nyc.dirA.20180621-131000.UTC.anon.pcap/', 'equinix-nyc.dirA.20180621-131100.UTC.anon.pcap/', \n",
    "           'equinix-nyc.dirA.20180816-130900.UTC.anon.pcap/', 'equinix-nyc.dirA.20180816-131000.UTC.anon.pcap/', 'equinix-nyc.dirA.20180816-131100.UTC.anon.pcap/', ]\n",
    "# # diff dataset\n",
    "# datasets = ['equinix-nyc.dirA.20181018-130900.UTC.anon.pcap/', 'equinix-nyc.dirA.20181018-131000.UTC.anon.pcap/', 'equinix-nyc.dirA.20181018-131100.UTC.anon.pcap/', \n",
    "#            'equinix-nyc.dirA.20181115-130900.UTC.anon.pcap/', 'equinix-nyc.dirA.20181115-131000.UTC.anon.pcap/', 'equinix-nyc.dirA.20181115-131100.UTC.anon.pcap/', \n",
    "#            'equinix-nyc.dirA.20181220-130900.UTC.anon.pcap/', 'equinix-nyc.dirA.20181220-131000.UTC.anon.pcap/', 'equinix-nyc.dirA.20181220-131100.UTC.anon.pcap/', ]\n",
    "\n",
    "input_dir = './results/profiler/'\n",
    "output_dir = './results/profiler_per_pcap/'\n",
    "\n",
    "# iterate each file under input_dir\n",
    "for d in os.listdir(input_dir):\n",
    "    filename = input_dir + d\n",
    "    \n",
    "    if os.path.isfile(filename):\n",
    "        with open(filename) as f:\n",
    "            js = json.loads(f.read())\n",
    "            print('Input: ' + filename)\n",
    "            \n",
    "            # split profile by 1 single pcap\n",
    "            for i, date in enumerate(datasets):\n",
    "                tmp = date.split('.')[2]\n",
    "                path = output_dir + tmp + '/'\n",
    "                # print(path)\n",
    "                if not os.path.exists(path):\n",
    "                    os.makedirs(path)\n",
    "                \n",
    "                # key: metric, row (number), width (byte)\n",
    "                ret = {}\n",
    "                for m in js:\n",
    "                    ret[m] = {}\n",
    "                    for r in js[m]:\n",
    "                        ret[m][r] = {}\n",
    "                        for w in js[m][r]:\n",
    "                            ret[m][r][w] = []\n",
    "                            ret[m][r][w].append(js[m][r][w][i*2])\n",
    "                            ret[m][r][w].append(js[m][r][w][i*2+1])\n",
    "                # print(ret)\n",
    "                path = f'{path}{d}'\n",
    "                print('Output: ' + path)\n",
    "                with open(path, 'w') as out:\n",
    "                    json.dump(ret, out)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f7bd2b8-9dcf-48c9-b32b-b729cfc495c2",
   "metadata": {},
   "source": [
    "## Split data for different number of pcaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74a957ac-a2d9-4082-8c45-6b78099ab66b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: ./results/profiler/cs_level_1_result.json\n",
      "Output: ./results/profiler_num_of_pcaps/pcap_1/cs_level_1_result.json\n",
      "Output: ./results/profiler_num_of_pcaps/pcap_3/cs_level_1_result.json\n",
      "Output: ./results/profiler_num_of_pcaps/pcap_5/cs_level_1_result.json\n",
      "Output: ./results/profiler_num_of_pcaps/pcap_7/cs_level_1_result.json\n",
      "Output: ./results/profiler_num_of_pcaps/pcap_9/cs_level_1_result.json\n",
      "Input: ./results/profiler/mrac_level_8_result.json\n",
      "Output: ./results/profiler_num_of_pcaps/pcap_1/mrac_level_8_result.json\n",
      "Output: ./results/profiler_num_of_pcaps/pcap_3/mrac_level_8_result.json\n",
      "Output: ./results/profiler_num_of_pcaps/pcap_5/mrac_level_8_result.json\n",
      "Output: ./results/profiler_num_of_pcaps/pcap_7/mrac_level_8_result.json\n",
      "Output: ./results/profiler_num_of_pcaps/pcap_9/mrac_level_8_result.json\n",
      "Input: ./results/profiler/hll_level_1_result.json\n",
      "Output: ./results/profiler_num_of_pcaps/pcap_1/hll_level_1_result.json\n",
      "Output: ./results/profiler_num_of_pcaps/pcap_3/hll_level_1_result.json\n",
      "Output: ./results/profiler_num_of_pcaps/pcap_5/hll_level_1_result.json\n",
      "Output: ./results/profiler_num_of_pcaps/pcap_7/hll_level_1_result.json\n",
      "Output: ./results/profiler_num_of_pcaps/pcap_9/hll_level_1_result.json\n",
      "Input: ./results/profiler/univmon_level_16_result.json\n",
      "Output: ./results/profiler_num_of_pcaps/pcap_1/univmon_level_16_result.json\n",
      "Output: ./results/profiler_num_of_pcaps/pcap_3/univmon_level_16_result.json\n",
      "Output: ./results/profiler_num_of_pcaps/pcap_5/univmon_level_16_result.json\n",
      "Output: ./results/profiler_num_of_pcaps/pcap_7/univmon_level_16_result.json\n",
      "Output: ./results/profiler_num_of_pcaps/pcap_9/univmon_level_16_result.json\n",
      "Input: ./results/profiler/lc_level_1_result.json\n",
      "Output: ./results/profiler_num_of_pcaps/pcap_1/lc_level_1_result.json\n",
      "Output: ./results/profiler_num_of_pcaps/pcap_3/lc_level_1_result.json\n",
      "Output: ./results/profiler_num_of_pcaps/pcap_5/lc_level_1_result.json\n",
      "Output: ./results/profiler_num_of_pcaps/pcap_7/lc_level_1_result.json\n",
      "Output: ./results/profiler_num_of_pcaps/pcap_9/lc_level_1_result.json\n",
      "Input: ./results/profiler/ll_level_1_result.json\n",
      "Output: ./results/profiler_num_of_pcaps/pcap_1/ll_level_1_result.json\n",
      "Output: ./results/profiler_num_of_pcaps/pcap_3/ll_level_1_result.json\n",
      "Output: ./results/profiler_num_of_pcaps/pcap_5/ll_level_1_result.json\n",
      "Output: ./results/profiler_num_of_pcaps/pcap_7/ll_level_1_result.json\n",
      "Output: ./results/profiler_num_of_pcaps/pcap_9/ll_level_1_result.json\n",
      "Input: ./results/profiler/mrb_level_8_result.json\n",
      "Output: ./results/profiler_num_of_pcaps/pcap_1/mrb_level_8_result.json\n",
      "Output: ./results/profiler_num_of_pcaps/pcap_3/mrb_level_8_result.json\n",
      "Output: ./results/profiler_num_of_pcaps/pcap_5/mrb_level_8_result.json\n",
      "Output: ./results/profiler_num_of_pcaps/pcap_7/mrb_level_8_result.json\n",
      "Output: ./results/profiler_num_of_pcaps/pcap_9/mrb_level_8_result.json\n",
      "Input: ./results/profiler/cm_level_1_result.json\n",
      "Output: ./results/profiler_num_of_pcaps/pcap_1/cm_level_1_result.json\n",
      "Output: ./results/profiler_num_of_pcaps/pcap_3/cm_level_1_result.json\n",
      "Output: ./results/profiler_num_of_pcaps/pcap_5/cm_level_1_result.json\n",
      "Output: ./results/profiler_num_of_pcaps/pcap_7/cm_level_1_result.json\n",
      "Output: ./results/profiler_num_of_pcaps/pcap_9/cm_level_1_result.json\n"
     ]
    }
   ],
   "source": [
    "input_dir = './results/profiler/'\n",
    "output_dir = './results/profiler_num_of_pcaps/'\n",
    "\n",
    "nums_of_pcap = [1, 3, 5, 7, 9]\n",
    "\n",
    "# iterate each file under input_dir\n",
    "for d in os.listdir(input_dir):\n",
    "    filename = input_dir + d\n",
    "    \n",
    "    if os.path.isfile(filename):\n",
    "        with open(filename) as f:\n",
    "            js = json.loads(f.read())\n",
    "            print('Input: ' + filename)\n",
    "\n",
    "            for num in nums_of_pcap:\n",
    "                # print(num)\n",
    "                # key: metric, row (number), width (byte)\n",
    "                ret = {}\n",
    "                for m in js:\n",
    "                    ret[m] = {}\n",
    "                    for r in js[m]:\n",
    "                        ret[m][r] = {}\n",
    "                        for w in js[m][r]:\n",
    "                            ret[m][r][w] = js[m][r][w][0:num*2]\n",
    "                # print(ret)\n",
    "                path = output_dir + f'pcap_{num}/'\n",
    "                if not os.path.exists(path):\n",
    "                    os.makedirs(path)\n",
    "                print('Output: ' + path + d)\n",
    "                with open(path + d, 'w') as out:\n",
    "                    json.dump(ret, out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93f1db65-6f0a-40d2-9a59-bcfa1683c928",
   "metadata": {},
   "source": [
    "## Split data by epochs on selecting date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "13812755-89e2-4e53-ae1e-cc3a05c0e591",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: ./results/profiler/cs_level_1_result.json\n",
      "Output: ./results/profiler_per_epoch/20180621/epoch_0/cs_level_1_result.json\n",
      "Output: ./results/profiler_per_epoch/20180621/epoch_1/cs_level_1_result.json\n",
      "Output: ./results/profiler_per_epoch/20180621/epoch_2/cs_level_1_result.json\n",
      "Output: ./results/profiler_per_epoch/20180621/epoch_3/cs_level_1_result.json\n",
      "Output: ./results/profiler_per_epoch/20180621/epoch_4/cs_level_1_result.json\n",
      "Output: ./results/profiler_per_epoch/20180621/epoch_5/cs_level_1_result.json\n",
      "Input: ./results/profiler/mrac_level_8_result.json\n",
      "Output: ./results/profiler_per_epoch/20180621/epoch_0/mrac_level_8_result.json\n",
      "Output: ./results/profiler_per_epoch/20180621/epoch_1/mrac_level_8_result.json\n",
      "Output: ./results/profiler_per_epoch/20180621/epoch_2/mrac_level_8_result.json\n",
      "Output: ./results/profiler_per_epoch/20180621/epoch_3/mrac_level_8_result.json\n",
      "Output: ./results/profiler_per_epoch/20180621/epoch_4/mrac_level_8_result.json\n",
      "Output: ./results/profiler_per_epoch/20180621/epoch_5/mrac_level_8_result.json\n",
      "Input: ./results/profiler/hll_level_1_result.json\n",
      "Output: ./results/profiler_per_epoch/20180621/epoch_0/hll_level_1_result.json\n",
      "Output: ./results/profiler_per_epoch/20180621/epoch_1/hll_level_1_result.json\n",
      "Output: ./results/profiler_per_epoch/20180621/epoch_2/hll_level_1_result.json\n",
      "Output: ./results/profiler_per_epoch/20180621/epoch_3/hll_level_1_result.json\n",
      "Output: ./results/profiler_per_epoch/20180621/epoch_4/hll_level_1_result.json\n",
      "Output: ./results/profiler_per_epoch/20180621/epoch_5/hll_level_1_result.json\n",
      "Input: ./results/profiler/univmon_level_16_result.json\n",
      "Output: ./results/profiler_per_epoch/20180621/epoch_0/univmon_level_16_result.json\n",
      "Output: ./results/profiler_per_epoch/20180621/epoch_1/univmon_level_16_result.json\n",
      "Output: ./results/profiler_per_epoch/20180621/epoch_2/univmon_level_16_result.json\n",
      "Output: ./results/profiler_per_epoch/20180621/epoch_3/univmon_level_16_result.json\n",
      "Output: ./results/profiler_per_epoch/20180621/epoch_4/univmon_level_16_result.json\n",
      "Output: ./results/profiler_per_epoch/20180621/epoch_5/univmon_level_16_result.json\n",
      "Input: ./results/profiler/lc_level_1_result.json\n",
      "Output: ./results/profiler_per_epoch/20180621/epoch_0/lc_level_1_result.json\n",
      "Output: ./results/profiler_per_epoch/20180621/epoch_1/lc_level_1_result.json\n",
      "Output: ./results/profiler_per_epoch/20180621/epoch_2/lc_level_1_result.json\n",
      "Output: ./results/profiler_per_epoch/20180621/epoch_3/lc_level_1_result.json\n",
      "Output: ./results/profiler_per_epoch/20180621/epoch_4/lc_level_1_result.json\n",
      "Output: ./results/profiler_per_epoch/20180621/epoch_5/lc_level_1_result.json\n",
      "Input: ./results/profiler/ll_level_1_result.json\n",
      "Output: ./results/profiler_per_epoch/20180621/epoch_0/ll_level_1_result.json\n",
      "Output: ./results/profiler_per_epoch/20180621/epoch_1/ll_level_1_result.json\n",
      "Output: ./results/profiler_per_epoch/20180621/epoch_2/ll_level_1_result.json\n",
      "Output: ./results/profiler_per_epoch/20180621/epoch_3/ll_level_1_result.json\n",
      "Output: ./results/profiler_per_epoch/20180621/epoch_4/ll_level_1_result.json\n",
      "Output: ./results/profiler_per_epoch/20180621/epoch_5/ll_level_1_result.json\n",
      "Input: ./results/profiler/mrb_level_8_result.json\n",
      "Output: ./results/profiler_per_epoch/20180621/epoch_0/mrb_level_8_result.json\n",
      "Output: ./results/profiler_per_epoch/20180621/epoch_1/mrb_level_8_result.json\n",
      "Output: ./results/profiler_per_epoch/20180621/epoch_2/mrb_level_8_result.json\n",
      "Output: ./results/profiler_per_epoch/20180621/epoch_3/mrb_level_8_result.json\n",
      "Output: ./results/profiler_per_epoch/20180621/epoch_4/mrb_level_8_result.json\n",
      "Output: ./results/profiler_per_epoch/20180621/epoch_5/mrb_level_8_result.json\n",
      "Input: ./results/profiler/cm_level_1_result.json\n",
      "Output: ./results/profiler_per_epoch/20180621/epoch_0/cm_level_1_result.json\n",
      "Output: ./results/profiler_per_epoch/20180621/epoch_1/cm_level_1_result.json\n",
      "Output: ./results/profiler_per_epoch/20180621/epoch_2/cm_level_1_result.json\n",
      "Output: ./results/profiler_per_epoch/20180621/epoch_3/cm_level_1_result.json\n",
      "Output: ./results/profiler_per_epoch/20180621/epoch_4/cm_level_1_result.json\n",
      "Output: ./results/profiler_per_epoch/20180621/epoch_5/cm_level_1_result.json\n"
     ]
    }
   ],
   "source": [
    "input_dir = './results/profiler/'\n",
    "output_dir = './results/profiler_per_epoch/'\n",
    "\n",
    "# date = '20180517'\n",
    "# index_list = [0, 1, 2, 3, 4, 5] # the index of this date on profiler\n",
    "date = '20180621'\n",
    "index_list = [6, 7, 8, 9, 10, 11] # the index of this date on profiler\n",
    "# date = '20180816'\n",
    "# index_list = [12, 13, 14, 15, 16, 17] # the index of this date on profiler\n",
    "one_min = 60 # i pcap has 60 sec\n",
    "epoch = 30 # 30 sec\n",
    "\n",
    "# iterate each file under input_dir\n",
    "for d in os.listdir(input_dir):\n",
    "    filename = input_dir + d\n",
    "    \n",
    "    if os.path.isfile(filename):\n",
    "        with open(filename) as f:\n",
    "            js = json.loads(f.read())\n",
    "            print('Input: ' + filename)\n",
    "            \n",
    "            cnt = 0\n",
    "            # key: metric, row (number), width (byte)\n",
    "            for idx in index_list:\n",
    "                ret = {}\n",
    "                for m in js:\n",
    "                    ret[m] = {}\n",
    "                    for r in js[m]:\n",
    "                        ret[m][r] = {}\n",
    "                        for w in js[m][r]:\n",
    "                            ret[m][r][w] = [js[m][r][w][idx]]\n",
    "                # print(ret)\n",
    "                path = output_dir + f'{date}/' + f'epoch_{cnt}/'\n",
    "                if not os.path.exists(path):\n",
    "                    os.makedirs(path)\n",
    "                print('Output: ' + path + d)\n",
    "                with open(path + d, 'w') as out:\n",
    "                    json.dump(ret, out)\n",
    "                cnt += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abad2dda-dfc2-4d48-90e8-0706fbbaacc4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
