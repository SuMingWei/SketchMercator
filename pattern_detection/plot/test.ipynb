{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import numpy as np\n",
    "import random\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import seaborn as sns\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_sum_data(algo='cm', row=3, width=4096, level=1, seed=1, count=1, flowkey='srcIP', \n",
    "              epochs=['10'], dataset='zipf2a_3_caida20180517_7.pcap', window_size=200):\n",
    "    res = []\n",
    "    for epoch in epochs:\n",
    "        \n",
    "        path = f\"../lstm/SketchPatternQuery/{algo}/{dataset}/\"\\\n",
    "                f\"{flowkey}/row_{row}_width_{width}_level_{level}_epoch_{epoch}_count_{count}_seed_{seed}/\"\n",
    "        \n",
    "        for dir in sorted(os.listdir(path)):\n",
    "            p = os.path.join(path, dir)\n",
    "            if os.path.isdir(p): \n",
    "                window_dir = \"summation_\" + str(window_size)\n",
    "                final_full_path = os.path.join(path, dir, window_dir, \"final_topk_summation.txt\")    \n",
    "                dynamic_full_path = os.path.join(path, dir, window_dir, \"dynamic_topk_summation.txt\")    \n",
    "                \n",
    "                with open(final_full_path, 'r') as f:\n",
    "                    line = f.readline().strip()\n",
    "                    final_list = [int(num) for num in line.split()]\n",
    "                    res.append(final_list)\n",
    "                    \n",
    "                with open(dynamic_full_path, 'r') as f:\n",
    "                    line = f.readline().strip()\n",
    "                    dynamic_list = [int(num) for num in line.split()]\n",
    "                    res.append(dynamic_list)\n",
    "            \n",
    "    return res\n",
    "\n",
    "# read_sum_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_total_size_data(algo='cm', row=3, width=4096, level=1, seed=1, count=1, flowkey='srcIP', \n",
    "              epochs=['10'], dataset='caida20180517_10_caida20180816_0.pcap', window_size=200):\n",
    "    res = []\n",
    "    for epoch in epochs:\n",
    "        \n",
    "        path = f\"../lstm/SketchPatternQuery/{algo}/{dataset}/\"\\\n",
    "                f\"{flowkey}/row_{row}_width_{width}_level_{level}_epoch_{epoch}_count_{count}_seed_{seed}/\"\n",
    "        \n",
    "        for dir in sorted(os.listdir(path)):\n",
    "            p = os.path.join(path, dir)\n",
    "            if os.path.isdir(p): \n",
    "                window_dir = \"window_\" + str(window_size)\n",
    "                full_path = os.path.join(path, dir, window_dir,'total_flow_size.txt')    \n",
    "                with open(full_path, 'r') as f:\n",
    "                    for val in f:\n",
    "                        res.append(int(val))\n",
    "            \n",
    "    return res\n",
    "\n",
    "# read_total_size_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['caida20180816_3_caida20180517_7.pcap', 'caida20180816_4_caida20180517_6.pcap', 'caida20180816_5_caida20180517_5.pcap', 'caida20180816_6_caida20180517_4.pcap', 'caida20180816_7_caida20180517_3.pcap', 'caida20180816_8_caida20180517_2.pcap', 'caida20180517_10_caida20180816_0.pcap', 'caida20180816_10_caida20180816_0.pcap', 'zipf2a_10_caida20180816_0.pcap', 'zipf2b_10_caida20180816_0.pcap', 'zipf4_10_caida20180816_0.pcap']\n",
      "Total Pcap File Number: 11\n"
     ]
    }
   ],
   "source": [
    "## parameters\n",
    "\n",
    "name1 = [\"zipf2a\", \"zipf4\", \"zipf2b\"]\n",
    "name2 = [\"caida20180816\", \"caida20180517\"]\n",
    "\n",
    "lens = [[\"3\", \"7\"],\n",
    "        [\"4\", \"6\"],\n",
    "        [\"5\", \"5\"],\n",
    "        [\"6\", \"4\"],\n",
    "        [\"7\", \"3\"],\n",
    "        [\"8\", \"2\"],]\n",
    "\n",
    "pcap_file = []\n",
    "\n",
    "\n",
    "# # caida + caida\n",
    "for l in lens:\n",
    "    name = f'{name2[0]}_{l[0]}_{name2[1]}_{l[1]}.pcap'\n",
    "    pcap_file.append(name)\n",
    "\n",
    "    \n",
    "# single dataset\n",
    "pcap_file.append(\"caida20180517_10_caida20180816_0.pcap\")\n",
    "pcap_file.append(\"caida20180816_10_caida20180816_0.pcap\")\n",
    "pcap_file.append(\"zipf2a_10_caida20180816_0.pcap\") \n",
    "pcap_file.append(\"zipf2b_10_caida20180816_0.pcap\") \n",
    "pcap_file.append(\"zipf4_10_caida20180816_0.pcap\")\n",
    "\n",
    "\n",
    "# # caida + zipf\n",
    "# for n1 in name1:\n",
    "#     for l in lens:\n",
    "#         name = f'{name2[0]}_{l[0]}_{n1}_{l[1]}.pcap'\n",
    "#         pcap_file.append(name)\n",
    "\n",
    "\n",
    "# # zipf + caida\n",
    "# for n1 in name1:\n",
    "#     for n2 in name2:\n",
    "#         for l in lens:\n",
    "#             name = f'{n1}_{l[0]}_{n2}_{l[1]}.pcap'\n",
    "#             pcap_file.append(name)\n",
    "\n",
    "print(pcap_file)    \n",
    "print(f'Total Pcap File Number: {len(pcap_file)}')\n",
    "# widths = [2048, 4096, 8192, 16384, 32768, 65536, 131072]\n",
    "widths = [4096]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Both Final & Dynamic TopK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_final_dynamic_topk(algo='cm', row=3, width=[4096], level=1, seed=1, count=1, flowkey='srcIP', \n",
    "              epochs=['10'], datasets=['zipf2a_3_caida20180517_7.pcap'], window_size=200):\n",
    "    \n",
    "    res_sum = {}\n",
    "    res_var = {}\n",
    "    res_sec_var = {}\n",
    "    res_sum2 = {}\n",
    "    res_var2 = {}\n",
    "    res_sec_var2 = {}\n",
    "    label = []\n",
    "    answer = []\n",
    "    \n",
    "    for d in datasets:\n",
    "        for w in width:\n",
    "            name = f'{d[:-5]}_{w}'\n",
    "            res_var[name] = [None]\n",
    "            res_var2[name] = [None]\n",
    "            res_sec_var[name] = [None, None]\n",
    "            res_sec_var2[name] = [None, None]\n",
    "            \n",
    "            res = read_sum_data(algo, row, w, level, seed, count, flowkey, epochs, d, window_size)\n",
    "\n",
    "            label.append(name)\n",
    "            answer.append(int(d.split('_')[1]))\n",
    "            \n",
    "            res_sum[name] = res[0]\n",
    "            res_sum2[name] = res[1]\n",
    "            \n",
    "            for i in range(1, len(res[0])):\n",
    "                res_var[name].append(res[0][i] - res[0][i-1])\n",
    "                res_var2[name].append(res[1][i] - res[1][i-1])\n",
    "                \n",
    "            for i in range(2, len(res_var[name])):\n",
    "                res_sec_var[name].append(abs(res_var[name][i] - res_var[name][i-1]))\n",
    "                res_sec_var2[name].append(abs(res_var2[name][i] - res_var2[name][i-1]))\n",
    "            \n",
    "    # res = read_data(algo, row, width, level, seed, count, flowkey, epochs, dataset, type, window_size)\n",
    "    # print(label, len(label))\n",
    "    # print(res_sum, len(res_sum))\n",
    "    # print(res_var, len(res_var))\n",
    "    # print(res_sec_var, len(res_sec_var))\n",
    "    \n",
    "    # print(answer)\n",
    "    ignore = int(1000/window_size)\n",
    "    pred = []\n",
    "    pred2 = []\n",
    "    for i in range(len(label)):\n",
    "        # final\n",
    "        end = min(int(10*1000/window_size)+1-ignore, len(res_var[label[i]]))\n",
    "        # print(\"+++++++\")\n",
    "        # print(len(res_var[label[i]]))\n",
    "        # print(end-ignore-1)\n",
    "        # print(\"+++++++\")\n",
    "        var_max = max(res_var[label[i]][(1+ignore):end])\n",
    "        var_avg = sum(res_var[label[i]][(1+ignore):end]) / len(res_var[label[i]][(1+ignore):end])\n",
    "        var_diff = var_max - var_avg\n",
    "        # print(var_max, var_avg, var_diff)\n",
    "        max_idx = ignore+1\n",
    "        max_val = -1\n",
    "        for j in range(ignore+1, min(int(10*1000/window_size)+1-ignore, len(res_sec_var[label[i]]))):\n",
    "            if res_sec_var[label[i]][j] > max_val:\n",
    "                max_val = res_sec_var[label[i]][j] \n",
    "                max_idx = j\n",
    "                \n",
    "        pred.append((max_idx-1)*window_size/1000)\n",
    "        \n",
    "        # dynamic\n",
    "        var_max2 = max(res_var2[label[i]][(1+ignore):end])\n",
    "        var_avg2 = sum(res_var2[label[i]][(1+ignore):end]) / len(res_var2[label[i]][(1+ignore):end])\n",
    "        var_diff2 = var_max2 - var_avg2\n",
    "        # print(var_max, var_avg, var_diff)\n",
    "        max_idx2 = ignore+1\n",
    "        max_val2 = -1\n",
    "        for j in range(ignore+1, min(int(10*1000/window_size)+1-ignore, len(res_sec_var2[label[i]]))):\n",
    "            if res_sec_var2[label[i]][j] > max_val2:\n",
    "                max_val2 = res_sec_var2[label[i]][j] \n",
    "                max_idx2 = j\n",
    "                \n",
    "        pred2.append((max_idx2-1)*window_size/1000)\n",
    "        \n",
    "        print(i)\n",
    "        print(label[i])\n",
    "        print('\\tFinal TopK')\n",
    "        print('\\t\\t', var_max, var_avg, var_diff)\n",
    "        print('\\t\\t', max(res_sec_var[label[i]][(1+ignore):end]), sum(res_sec_var[label[i]][(1+ignore):end]) / len(res_sec_var[label[i]][(1+ignore):end]), max(res_sec_var[label[i]][(1+ignore):end]) - (sum(res_sec_var[label[i]][(1+ignore):end]) / len(res_sec_var[label[i]][(1+ignore):end])))\n",
    "        print('\\t\\t', pred[i], answer[i])\n",
    "        print('\\tDynamic TopK')\n",
    "        print('\\t\\t', var_max2, var_avg2, var_diff2)\n",
    "        print('\\t\\t', max(res_sec_var2[label[i]][(1+ignore):end]), sum(res_sec_var2[label[i]][(1+ignore):end]) / len(res_sec_var2[label[i]][(1+ignore):end]), max(res_sec_var2[label[i]][(1+ignore):end]) - (sum(res_sec_var2[label[i]][(1+ignore):end]) / len(res_sec_var2[label[i]][(1+ignore):end])))\n",
    "        print('\\t\\t', pred2[i], answer[i])\n",
    "        print()\n",
    "        \n",
    "    succ = 0\n",
    "    succ2 = 0\n",
    "    for i in range(len(pred)):\n",
    "        if abs(pred[i] - answer[i]) < 1.0:\n",
    "            succ += 1\n",
    "            \n",
    "        if abs(pred2[i] - answer[i]) < 1.0:\n",
    "            succ2 += 1\n",
    "    \n",
    "    print(f'final   topk predict: {succ}/{len(pred)} {succ*100/len(pred)}%')\n",
    "    print(f'dynamic topk predict: {succ2}/{len(pred2)} {succ2*100/len(pred2)}%')\n",
    "        \n",
    "# predict_final_dynamic_topk(width=widths, datasets=pcap_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_both_topk(algo='cm', row=3, width=4096, level=1, seed=1, count=1, flowkey='srcIP', \n",
    "              epochs=['10'], dataset='zipf2a_3_caida20180517_7.pcap', window_size=500):\n",
    "    \n",
    "    labels = [\"Final TopK Sum\", \"Dynamic TopK Sum\", \"Final TopK Var\", \"Dynamic TopK Var\", \"Final TopK Sec Var\", \"Dynamic TopK Sec Var\"]\n",
    "    labels = [\"Final TopK Sum\", \"Dynamic TopK Sum\", \"Final TopK Sec Var\", \"Dynamic TopK Sec Var\"]\n",
    "\n",
    "    # sum\n",
    "    res= read_sum_data(algo, row, width, level, seed, count, flowkey, epochs, dataset, window_size)\n",
    "    \n",
    "    # variation\n",
    "    fin_res_var = [None]\n",
    "    dyn_res_var = [None]\n",
    "    for i in range(1, len(res[0])):\n",
    "        fin_res_var.append(res[0][i] - res[0][i-1])\n",
    "        dyn_res_var.append(res[1][i] - res[1][i-1])\n",
    "        \n",
    "    # res.append(fin_res_var)\n",
    "    # res.append(dyn_res_var)\n",
    "    \n",
    "    # second variation\n",
    "    fin_sec_res_var = [None, None]\n",
    "    dyn_sec_res_var = [None, None]\n",
    "    for i in range(2, len(res[0])):\n",
    "        fin_sec_res_var.append(abs(fin_res_var[i] - fin_res_var[i-1]))\n",
    "        dyn_sec_res_var.append(abs(dyn_res_var[i] - dyn_res_var[i-1]))\n",
    "        \n",
    "    res.append(fin_sec_res_var)\n",
    "    res.append(dyn_sec_res_var)\n",
    "    \n",
    "    print(labels, len(labels))\n",
    "    print(res, len(res))\n",
    "    print(fin_sec_res_var, len(res))\n",
    "    print(dyn_sec_res_var, len(res))\n",
    "    print(f'max: {max(fin_res_var[1:])}, avg: {sum(fin_res_var[1:])/len(fin_res_var[1:])}, diff: {max(fin_res_var[1:]) - (sum(fin_res_var[1:])/len(fin_res_var[1:]))}')\n",
    "    print(f'max: {max(dyn_res_var[1:])}, avg: {sum(dyn_res_var[1:])/len(dyn_res_var[1:])}, diff: {max(dyn_res_var[1:]) - (sum(dyn_res_var[1:])/len(dyn_res_var[1:]))}')\n",
    "    \n",
    "    plt.figure(figsize=(12, 4))\n",
    "    \n",
    "    # sns.lineplot(data=res, dashes=False, markers=True, markersize=4)\n",
    "    # for i, data_set in enumerate(res):\n",
    "    #     plt.plot(range(1,21), data_set, label=f'Data Set {i + 1}')\n",
    "        \n",
    "    # print(dataset)\n",
    "    for i in range(len(res)):\n",
    "        plt.plot(res[i], label=labels[i])\n",
    "        \n",
    "\n",
    "    # Add labels and legend\n",
    "    plt.xlabel('Time (sec)')\n",
    "    plt.ylabel('Value')\n",
    "    plt.title('%s Fixed Window (Window Size = %d)' % (dataset, window_size))\n",
    "    # plt.axhline(10000, c=\"black\")\n",
    "    ticks = [i for i in range(int(10*1000/window_size) + 1)]\n",
    "    adjusted_ticks = [tick * (window_size / 1000) for tick in ticks[0::int(1000 / window_size)]]\n",
    "    plt.xticks(ticks[0::int(1000/window_size)], adjusted_ticks)\n",
    "    plt.legend(loc='upper left', ncol=math.ceil(len(res)/4))\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "# datasets = ['10_0.pcap/', '5_5.pcap/', '4_6.pcap/', '3_7.pcap/']\n",
    "datasets = [\"zipf2a_3_caida20180517_7.pcap/\"]\n",
    "# window_sizes = [100, 200, 500]\n",
    "window_sizes = [200]\n",
    "# plot_single_both(dataset=pcap_file[4], window_size=200)\n",
    "# plot_single_both(dataset=datasets[0], window_size=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Total Flow Size Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_with_total_size(algo='cm', row=3, width=[4096], level=1, seed=1, count=1, flowkey='srcIP', \n",
    "              epochs=['10'], datasets=['zipf2a_3_caida20180517_7.pcap'], window_size=200):\n",
    "    \n",
    "    res_sum = {}\n",
    "    res_var = {}\n",
    "    res_sec_var = {}\n",
    "    label = []\n",
    "    answer = []\n",
    "    \n",
    "    for d in datasets:\n",
    "        for w in width:\n",
    "            name = f'{d[:-5]}_{w}'\n",
    "            res_var[name] = [None]\n",
    "            res_sec_var[name] = [None, None]\n",
    "            \n",
    "            res = read_total_size_data(algo, row, w, level, seed, count, flowkey, epochs, d, window_size)\n",
    "\n",
    "            label.append(name)\n",
    "            answer.append(int(d.split('_')[1]))\n",
    "            \n",
    "            res_sum[name] = res\n",
    "            \n",
    "            for i in range(1, len(res)):\n",
    "                res_var[name].append(res[i] - res[i-1])\n",
    "                \n",
    "            for i in range(2, len(res_var[name])):\n",
    "                res_sec_var[name].append(abs(res_var[name][i] - res_var[name][i-1]))\n",
    "            \n",
    "    # res = read_data(algo, row, width, level, seed, count, flowkey, epochs, dataset, type, window_size)\n",
    "    # print(label, len(label))\n",
    "    # print(res_sum, len(res_sum))\n",
    "    # print(res_var, len(res_var))\n",
    "    # print(res_sec_var, len(res_sec_var))\n",
    "    \n",
    "    # print(answer)\n",
    "    ignore = int(1000/window_size)\n",
    "    pred = []\n",
    "    for i in range(len(label)):\n",
    "        # final\n",
    "        print(res_var[label[i]])\n",
    "        end = min(int(10*1000/window_size)+1-ignore, len(res_var[label[i]]))\n",
    "        \n",
    "        var_max = max(res_var[label[i]][1+ignore:end])\n",
    "        var_avg = sum(res_var[label[i]][1+ignore:end]) / len(res_var[label[i]][1+ignore:end])\n",
    "        var_diff = var_max - var_avg\n",
    "        # print(var_max, var_avg, var_diff)\n",
    "        max_idx = 1+ignore\n",
    "        max_val = -1\n",
    "        for j in range(1+ignore, min(int(10*1000/window_size)+1-ignore, len(res_sec_var[label[i]]))):\n",
    "            if res_sec_var[label[i]][j] > max_val:\n",
    "                max_val = res_sec_var[label[i]][j] \n",
    "                max_idx = j\n",
    "                \n",
    "        pred.append((max_idx-1)*window_size/1000)\n",
    "        \n",
    "        \n",
    "        print(i)\n",
    "        print(label[i])\n",
    "        print('\\tTotal Size')\n",
    "        print('\\t\\t', var_max, var_avg, var_diff)\n",
    "        print('\\t\\t', max(res_sec_var[label[i]][2:]), sum(res_sec_var[label[i]][2:]) / len(res_sec_var[label[i]][2:]), max(res_sec_var[label[i]][2:]) - (sum(res_sec_var[label[i]][2:]) / len(res_sec_var[label[i]][2:])))\n",
    "        print('\\t\\t', pred[i], answer[i])\n",
    "        print()\n",
    "        \n",
    "    succ = 0\n",
    "    for i in range(len(pred)):\n",
    "        if abs(pred[i] - answer[i]) < 1.0:\n",
    "            succ += 1\n",
    "    \n",
    "    print(f'total flow size predict: {succ}/{len(pred)} {succ*100/len(pred)}%')\n",
    "        \n",
    "# predict_with_total_size(width=widths, datasets=pcap_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_single_total_size(algo='cm', row=3, width=4096, level=1, seed=1, count=1, flowkey='srcIP', \n",
    "              epochs=['10'], dataset='zipf2a_3_caida20180517_7.pcap', window_size=500):\n",
    "    \n",
    "    # labels = [\"Final TopK Sum\", \"Dynamic TopK Sum\", \"Final TopK Var\", \"Dynamic TopK Var\", \"Final TopK Sec Var\", \"Dynamic TopK Sec Var\"]\n",
    "    # labels = [\"Final TopK Sum\", \"Dynamic TopK Sum\", \"Final TopK Sec Var\", \"Dynamic TopK Sec Var\"]\n",
    "    labels = [\"Final TopK Sum\", \"Final TopK Sec Var\",]\n",
    "\n",
    "    res = []\n",
    "    # sum\n",
    "    result = read_total_size_data(algo, row, width, level, seed, count, flowkey, epochs, dataset, window_size)\n",
    "    \n",
    "    res.append(result)\n",
    "    \n",
    "    # variation\n",
    "    fin_res_var = [None]\n",
    "    for i in range(1, len(result)):\n",
    "        fin_res_var.append(result[i] - result[i-1])\n",
    "        \n",
    "    # res.append(fin_res_var)\n",
    "    \n",
    "    # second variation\n",
    "    fin_sec_res_var = [None, None]\n",
    "    for i in range(2, len(result)):\n",
    "        fin_sec_res_var.append(abs(fin_res_var[i] - fin_res_var[i-1]))\n",
    "        \n",
    "    res.append(fin_sec_res_var)\n",
    "    \n",
    "    print(labels, len(labels))\n",
    "    print(res, len(res))\n",
    "    print(result)\n",
    "    print(fin_res_var)\n",
    "    print(fin_sec_res_var, len(res))\n",
    "    print(f'max: {max(fin_res_var[1:])}, avg: {sum(fin_res_var[1:])/len(fin_res_var[1:])}, diff: {max(fin_res_var[1:]) - (sum(fin_res_var[1:])/len(fin_res_var[1:]))}')\n",
    "    \n",
    "    plt.figure(figsize=(12, 4))\n",
    "    \n",
    "    # sns.lineplot(data=res, dashes=False, markers=True, markersize=4)\n",
    "    # for i, data_set in enumerate(res):\n",
    "    #     plt.plot(range(1,21), data_set, label=f'Data Set {i + 1}')\n",
    "        \n",
    "    # print(dataset)\n",
    "    for i in range(len(res)):\n",
    "        plt.plot(res[i], label=labels[i])\n",
    "        \n",
    "\n",
    "    # Add labels and legend\n",
    "    plt.xlabel('Time (sec)')\n",
    "    plt.ylabel('Value')\n",
    "    plt.title('%s Flow Size Variation (Window Size = %d)' % (dataset[:-5], window_size))\n",
    "    # plt.axhline(10000, c=\"black\")\n",
    "    ticks = [i for i in range(int(10*1000/window_size) + 1)]\n",
    "    adjusted_ticks = [tick * (window_size / 1000) for tick in ticks[0::int(1000 / window_size)]]\n",
    "    plt.xticks(ticks[0::int(1000/window_size)], adjusted_ticks)\n",
    "    plt.legend(loc='upper left', ncol=math.ceil(len(res)/4))\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "# datasets = ['10_0.pcap/', '5_5.pcap/', '4_6.pcap/', '3_7.pcap/']\n",
    "datasets = [\"zipf2a_3_caida20180517_7.pcap/\"]\n",
    "# window_sizes = [100, 200, 500]\n",
    "window_sizes = [200]\n",
    "# plot_single_both(dataset=pcap_file[4], window_size=200)\n",
    "# plot_single_both(dataset=datasets[0], window_size=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# changing_time_predict_final_topk(width=widths, datasets=pcap_file)\n",
    "# plot_single_final_topk(dataset=pcap_file[0], type_=\"accumulate.txt\", window_size=200)\n",
    "\n",
    "# predict_final_dynamic_topk(width=widths, datasets=pcap_file)\n",
    "# plot_both_topk(dataset=pcap_file[0], window_size=200)\n",
    "\n",
    "# predict_with_total_size(width=widths, datasets=pcap_file)\n",
    "# plot_single_total_size(dataset=pcap_file[1], window_size=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict Final TopK & Dynamic TopK & Total Flow Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(algo='cm', row=3, width=[4096], level=1, seed=1, count=1, flowkey='srcIP', \n",
    "              epochs=['10'], datasets=['zipf2a_3_caida20180517_7.pcap'], window_size=200):\n",
    "    \n",
    "    res_sum = {}\n",
    "    res_var = {}\n",
    "    res_sec_var = {}\n",
    "    \n",
    "    res_sum2 = {}\n",
    "    res_var2 = {}\n",
    "    res_sec_var2 = {}\n",
    "    \n",
    "    res_sum3 = {}\n",
    "    res_var3 = {}\n",
    "    res_sec_var3 = {}\n",
    "    \n",
    "    label = []\n",
    "    answer = []\n",
    "    \n",
    "    for d in datasets:\n",
    "        for w in width:\n",
    "            name = f'{d[:-5]}_{w}'\n",
    "            res_var[name] = [None]\n",
    "            res_var2[name] = [None]\n",
    "            res_var3[name] = [None]\n",
    "            res_sec_var[name] = [None, None]\n",
    "            res_sec_var2[name] = [None, None]\n",
    "            res_sec_var3[name] = [None, None]\n",
    "            \n",
    "            res = read_sum_data(algo, row, w, level, seed, count, flowkey, epochs, d, window_size)\n",
    "            res_total = read_total_size_data(algo, row, w, level, seed, count, flowkey, epochs, d, window_size)\n",
    "\n",
    "            label.append(name)\n",
    "            answer.append(int(d.split('_')[1]))\n",
    "            \n",
    "            res_sum[name] = res[0]\n",
    "            res_sum2[name] = res[1]\n",
    "            res_sum3[name] = res_total\n",
    "            \n",
    "            for i in range(1, len(res[0])):\n",
    "                res_var[name].append(res[0][i] - res[0][i-1])\n",
    "                res_var2[name].append(res[1][i] - res[1][i-1])\n",
    "                res_var3[name].append(res_total[i] - res_total[i-1])\n",
    "                \n",
    "            for i in range(2, len(res_var[name])):\n",
    "                res_sec_var[name].append(abs(res_var[name][i] - res_var[name][i-1]))\n",
    "                res_sec_var2[name].append(abs(res_var2[name][i] - res_var2[name][i-1]))\n",
    "                res_sec_var3[name].append(abs(res_var3[name][i] - res_var3[name][i-1]))\n",
    "            \n",
    "    # res = read_data(algo, row, width, level, seed, count, flowkey, epochs, dataset, type, window_size)\n",
    "    # print(label, len(label))\n",
    "    # print(res_sum, len(res_sum))\n",
    "    # print(res_var, len(res_var))\n",
    "    # print(res_sec_var, len(res_sec_var))\n",
    "    \n",
    "    # print(answer)\n",
    "    ignore = int(1000/window_size)\n",
    "    pred = []\n",
    "    pred2 = []\n",
    "    pred3 = []\n",
    "    for i in range(len(label)):\n",
    "        # final\n",
    "        end = min(int(10*1000/window_size)+1-ignore, len(res_var[label[i]]))\n",
    "        # print(\"+++++++\")\n",
    "        # print(len(res_var[label[i]]))\n",
    "        # print(end-ignore-1)\n",
    "        # print(\"+++++++\")\n",
    "        var_max = max(res_var[label[i]][(1+ignore):end])\n",
    "        var_avg = sum(res_var[label[i]][(1+ignore):end]) / len(res_var[label[i]][(1+ignore):end])\n",
    "        var_diff = var_max - var_avg\n",
    "        # print(var_max, var_avg, var_diff)\n",
    "        max_idx = ignore+1\n",
    "        max_val = -1\n",
    "        for j in range(ignore+1, min(int(10*1000/window_size)+1-ignore, len(res_sec_var[label[i]]))):\n",
    "            if res_sec_var[label[i]][j] > max_val:\n",
    "                max_val = res_sec_var[label[i]][j] \n",
    "                max_idx = j\n",
    "                \n",
    "        pred.append((max_idx-1)*window_size/1000)\n",
    "        \n",
    "        # dynamic\n",
    "        var_max2 = max(res_var2[label[i]][(1+ignore):end])\n",
    "        var_avg2 = sum(res_var2[label[i]][(1+ignore):end]) / len(res_var2[label[i]][(1+ignore):end])\n",
    "        var_diff2 = var_max2 - var_avg2\n",
    "        # print(var_max, var_avg, var_diff)\n",
    "        max_idx2 = ignore+1\n",
    "        max_val2 = -1\n",
    "        for j in range(ignore+1, min(int(10*1000/window_size)+1-ignore, len(res_sec_var2[label[i]]))):\n",
    "            if res_sec_var2[label[i]][j] > max_val2:\n",
    "                max_val2 = res_sec_var2[label[i]][j] \n",
    "                max_idx2 = j\n",
    "                \n",
    "        pred2.append((max_idx2-1)*window_size/1000)\n",
    "        \n",
    "        # total flow size\n",
    "        var_max3 = max(res_var3[label[i]][(1+ignore):end])\n",
    "        var_avg3 = sum(res_var3[label[i]][(1+ignore):end]) / len(res_var3[label[i]][(1+ignore):end])\n",
    "        var_diff3 = var_max3 - var_avg3\n",
    "        # print(var_max, var_avg, var_diff)\n",
    "        max_idx3 = ignore+1\n",
    "        max_val3 = -1\n",
    "        for j in range(ignore+1, min(int(10*1000/window_size)+1-ignore, len(res_sec_var3[label[i]]))):\n",
    "            if res_sec_var3[label[i]][j] > max_val3:\n",
    "                max_val3 = res_sec_var3[label[i]][j] \n",
    "                max_idx3 = j\n",
    "                \n",
    "        pred3.append((max_idx3-1)*window_size/1000)\n",
    "        \n",
    "        print(i)\n",
    "        print(label[i])\n",
    "        print('\\tFinal TopK')\n",
    "        print('\\t\\t', var_max, var_avg, var_diff)\n",
    "        print('\\t\\t', max(res_sec_var[label[i]][(1+ignore):end]), sum(res_sec_var[label[i]][(1+ignore):end]) / len(res_sec_var[label[i]][(1+ignore):end]), max(res_sec_var[label[i]][(1+ignore):end]) - (sum(res_sec_var[label[i]][(1+ignore):end]) / len(res_sec_var[label[i]][(1+ignore):end])))\n",
    "        print('\\t\\t', pred[i], answer[i])\n",
    "        print('\\tDynamic TopK')\n",
    "        print('\\t\\t', var_max2, var_avg2, var_diff2)\n",
    "        print('\\t\\t', max(res_sec_var2[label[i]][(1+ignore):end]), sum(res_sec_var2[label[i]][(1+ignore):end]) / len(res_sec_var2[label[i]][(1+ignore):end]), max(res_sec_var2[label[i]][(1+ignore):end]) - (sum(res_sec_var2[label[i]][(1+ignore):end]) / len(res_sec_var2[label[i]][(1+ignore):end])))\n",
    "        print('\\t\\t', pred2[i], answer[i])\n",
    "        print('\\tTotal Flow ')\n",
    "        print('\\t\\t', var_max3, var_avg3, var_diff3)\n",
    "        print('\\t\\t', max(res_sec_var3[label[i]][(1+ignore):end]), sum(res_sec_var3[label[i]][(1+ignore):end]) / len(res_sec_var3[label[i]][(1+ignore):end]), max(res_sec_var3[label[i]][(1+ignore):end]) - (sum(res_sec_var3[label[i]][(1+ignore):end]) / len(res_sec_var3[label[i]][(1+ignore):end])))\n",
    "        print('\\t\\t', pred3[i], answer[i])\n",
    "        print()\n",
    "        \n",
    "    succ = 0\n",
    "    succ2 = 0\n",
    "    succ3 = 0\n",
    "\n",
    "    for i in range(len(pred)):\n",
    "        if abs(pred[i] - answer[i]) < 1.0:\n",
    "            succ += 1\n",
    "            \n",
    "        if abs(pred2[i] - answer[i]) < 1.0:\n",
    "            succ2 += 1\n",
    "            \n",
    "        if abs(pred3[i] - answer[i]) < 1.0:\n",
    "            succ3 += 1\n",
    "    \n",
    "    print(f'final   topk predict: {succ}/{len(pred)} {succ*100/len(pred)}%')\n",
    "    print(f'dynamic topk predict: {succ2}/{len(pred2)} {succ2*100/len(pred2)}%')\n",
    "    print(f' total flow  predict: {succ3}/{len(pred3)} {succ3*100/len(pred3)}%')\n",
    "        \n",
    "# predict_final_dynamic_topk(width=widths, datasets=pcap_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "caida20180816_3_caida20180517_7_4096\n",
      "\tFinal TopK\n",
      "\t\t 8928 5316.075 3611.925\n",
      "\t\t 5274 853.475 4420.525\n",
      "\t\t 3.0 3\n",
      "\tDynamic TopK\n",
      "\t\t 8731 4722.225 4008.7749999999996\n",
      "\t\t 3064 1102.45 1961.55\n",
      "\t\t 3.8 3\n",
      "\tTotal Flow \n",
      "\t\t 121535 108175.925 13359.074999999997\n",
      "\t\t 36141 4725.3 31415.7\n",
      "\t\t 3.4 3\n",
      "\n",
      "1\n",
      "caida20180816_4_caida20180517_6_4096\n",
      "\tFinal TopK\n",
      "\t\t 8928 4700.0 4228.0\n",
      "\t\t 5155 793.675 4361.325\n",
      "\t\t 4.0 4\n",
      "\tDynamic TopK\n",
      "\t\t 7862 4141.45 3720.55\n",
      "\t\t 3831 1108.675 2722.325\n",
      "\t\t 4.0 4\n",
      "\tTotal Flow \n",
      "\t\t 121782 110026.95 11755.050000000003\n",
      "\t\t 36144 4571.45 31572.55\n",
      "\t\t 4.4 4\n",
      "\n",
      "2\n",
      "caida20180816_5_caida20180517_5_4096\n",
      "\tFinal TopK\n",
      "\t\t 10258 4117.85 6140.15\n",
      "\t\t 6809 1081.55 5727.45\n",
      "\t\t 5.0 5\n",
      "\tDynamic TopK\n",
      "\t\t 7665 3585.65 4079.35\n",
      "\t\t 3067 1082.4 1984.6\n",
      "\t\t 5.8 5\n",
      "\tTotal Flow \n",
      "\t\t 121782 111260.25 10521.75\n",
      "\t\t 36152 4460.375 31691.625\n",
      "\t\t 5.4 5\n",
      "\n",
      "3\n",
      "caida20180816_6_caida20180517_4_4096\n",
      "\tFinal TopK\n",
      "\t\t 6718 3665.825 3052.175\n",
      "\t\t 3096 1129.725 1966.275\n",
      "\t\t 6.8 6\n",
      "\tDynamic TopK\n",
      "\t\t 6567 3426.175 3140.825\n",
      "\t\t 3550 1072.35 2477.65\n",
      "\t\t 6.0 6\n",
      "\tTotal Flow \n",
      "\t\t 122866 112622.35 10243.649999999994\n",
      "\t\t 36153 4540.05 31612.95\n",
      "\t\t 6.4 6\n",
      "\n",
      "4\n",
      "caida20180816_7_caida20180517_3_4096\n",
      "\tFinal TopK\n",
      "\t\t 6447 4027.525 2419.475\n",
      "\t\t 3077 1004.65 2072.35\n",
      "\t\t 7.8 7\n",
      "\tDynamic TopK\n",
      "\t\t 6567 3784.825 2782.175\n",
      "\t\t 3890 1081.525 2808.475\n",
      "\t\t 7.0 7\n",
      "\tTotal Flow \n",
      "\t\t 122866 113211.325 9654.675000000003\n",
      "\t\t 36154 4292.3 31861.7\n",
      "\t\t 7.4 7\n",
      "\n",
      "5\n",
      "caida20180816_8_caida20180517_2_4096\n",
      "\tFinal TopK\n",
      "\t\t 7193 4395.525 2797.4750000000004\n",
      "\t\t 3190 1086.025 2103.975\n",
      "\t\t 8.0 8\n",
      "\tDynamic TopK\n",
      "\t\t 6567 4127.4 2439.6000000000004\n",
      "\t\t 3134 1058.575 2075.425\n",
      "\t\t 8.0 8\n",
      "\tTotal Flow \n",
      "\t\t 122866 114596.175 8269.824999999997\n",
      "\t\t 36162 4457.125 31704.875\n",
      "\t\t 8.4 8\n",
      "\n",
      "6\n",
      "caida20180517_10_caida20180816_0_4096\n",
      "\tFinal TopK\n",
      "\t\t 8916 6550.9 2365.1000000000004\n",
      "\t\t 4505 1051.125 3453.875\n",
      "\t\t 8.8 10\n",
      "\tDynamic TopK\n",
      "\t\t 8835 6174.45 2660.55\n",
      "\t\t 4505 1076.425 3428.575\n",
      "\t\t 8.8 10\n",
      "\tTotal Flow \n",
      "\t\t 115657 107195.3 8461.699999999997\n",
      "\t\t 11993 3195.75 8797.25\n",
      "\t\t 8.8 10\n",
      "\n",
      "7\n",
      "caida20180816_10_caida20180816_0_4096\n",
      "\tFinal TopK\n",
      "\t\t 8833 4899.275 3933.7250000000004\n",
      "\t\t 3545 1249.4 2295.6\n",
      "\t\t 8.4 10\n",
      "\tDynamic TopK\n",
      "\t\t 6567 4671.25 1895.75\n",
      "\t\t 2685 1068.625 1616.375\n",
      "\t\t 2.6 10\n",
      "\tTotal Flow \n",
      "\t\t 122866 117015.35 5850.649999999994\n",
      "\t\t 7402 2949.8 4452.2\n",
      "\t\t 7.2 10\n",
      "\n",
      "8\n",
      "zipf2a_10_caida20180816_0_4096\n",
      "\tFinal TopK\n",
      "\t\t 7962 4598.175 3363.825\n",
      "\t\t 3924 996.825 2927.175\n",
      "\t\t 8.4 10\n",
      "\tDynamic TopK\n",
      "\t\t 7600 4548.75 3051.25\n",
      "\t\t 3857 1042.0 2815.0\n",
      "\t\t 8.4 10\n",
      "\tTotal Flow \n",
      "\t\t 32211 27465.025 4745.9749999999985\n",
      "\t\t 7258 1899.925 5358.075\n",
      "\t\t 7.8 10\n",
      "\n",
      "9\n",
      "zipf2b_10_caida20180816_0_4096\n",
      "\tFinal TopK\n",
      "\t\t 9923 7119.775 2803.2250000000004\n",
      "\t\t 4160 1305.275 2854.725\n",
      "\t\t 3.2 10\n",
      "\tDynamic TopK\n",
      "\t\t 10096 6944.775 3151.2250000000004\n",
      "\t\t 4285 1350.85 2934.15\n",
      "\t\t 3.2 10\n",
      "\tTotal Flow \n",
      "\t\t 96011 83208.05 12802.949999999997\n",
      "\t\t 18609 3201.025 15407.975\n",
      "\t\t 3.2 10\n",
      "\n",
      "10\n",
      "zipf4_10_caida20180816_0_4096\n",
      "\tFinal TopK\n",
      "\t\t 2076 1370.125 705.875\n",
      "\t\t 1017 354.425 662.575\n",
      "\t\t 2.4 10\n",
      "\tDynamic TopK\n",
      "\t\t 2373 1355.6 1017.4000000000001\n",
      "\t\t 1584 397.275 1186.725\n",
      "\t\t 1.6 10\n",
      "\tTotal Flow \n",
      "\t\t 14247 10821.875 3425.125\n",
      "\t\t 2615 700.1 1914.9\n",
      "\t\t 3.2 10\n",
      "\n",
      "final   topk predict: 6/11 54.54545454545455%\n",
      "dynamic topk predict: 6/11 54.54545454545455%\n",
      " total flow  predict: 6/11 54.54545454545455%\n"
     ]
    }
   ],
   "source": [
    "predict(width=widths, datasets=pcap_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
