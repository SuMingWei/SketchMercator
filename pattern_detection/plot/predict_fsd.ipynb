{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import numpy as np\n",
    "import random\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import seaborn as sns\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_fsd_data(algo='cm', row=3, width=4096, level=1, seed=1, count=1, flowkey='srcIP', \n",
    "              epochs=['10'], dataset='caida0517-125w_10_.pcap', window_size=200):\n",
    "    res = []\n",
    "    for epoch in epochs:\n",
    "        \n",
    "        path = f\"../SketchPatternQuery/{algo}/{dataset}/\"\\\n",
    "                f\"{flowkey}/row_{row}_width_{width}_level_{level}_epoch_{epoch}_count_{count}_seed_{seed}/\"\n",
    "        \n",
    "        for dir in sorted(os.listdir(path)):\n",
    "            p = os.path.join(path, dir)\n",
    "            if os.path.isdir(p): \n",
    "                window_dir = \"window_\" + str(window_size)\n",
    "                dynamic_full_path = os.path.join(path, dir, window_dir, \"randk_summation\")\n",
    "                \n",
    "                for file in sorted(os.listdir(dynamic_full_path)):  \n",
    "                    fsd_file = os.path.join(dynamic_full_path, file)\n",
    "                    fsd = {}\n",
    "                    with open(fsd_file, 'r') as f:\n",
    "                        for line in f:\n",
    "                            fsd[int(line.strip().split()[0])] = int(line.strip().split()[1])\n",
    "                            \n",
    "                    res.append(fsd)\n",
    "            \n",
    "    return res\n",
    "\n",
    "# read_fsd_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['caida0517-500w_10_.pcap', 'caida0517-250w_10_.pcap', 'caida0517-125w_10_.pcap', 'caida0816-600w_10_.pcap', 'caida0816-300w_10_.pcap', 'caida0816-150w_10_.pcap', 'zipf2a-150w_10_.pcap', 'zipf2a-75w_10_.pcap', 'zipf2a-35w_10_.pcap', 'zipf2b-400w_10_.pcap', 'zipf2b-200w_10_.pcap', 'zipf2b-100w_10_.pcap', 'zipf4-60w_10_.pcap', 'zipf4-30w_10_.pcap', 'zipf4-15w_10_.pcap']\n",
      "Total Pcap File Number: 15\n"
     ]
    }
   ],
   "source": [
    "## parameters\n",
    "\n",
    "caida0517 = [\"caida0517-500w\", \"caida0517-250w\", \"caida0517-125w\"]\n",
    "caida0816 = [\"caida0816-600w\", \"caida0816-300w\", \"caida0816-150w\"]\n",
    "zipf2a = [\"zipf2a-150w\", \"zipf2a-75w\", \"zipf2a-35w\"]\n",
    "zipf2b = [\"zipf2b-400w\", \"zipf2b-200w\", \"zipf2b-100w\"]\n",
    "zipf4 = [\"zipf4-60w\", \"zipf4-30w\", \"zipf4-15w\"]\n",
    "\n",
    "\n",
    "lens = [\n",
    "        # [\"5\", \"5\"],\n",
    "        [\"6\", \"4\"],\n",
    "        # [\"7\", \"3\"],\n",
    "        # [\"8\", \"2\"],\n",
    "        ]\n",
    "\n",
    "pcap_file = []\n",
    "    \n",
    "# # single dataset\n",
    "pcap_file.append(\"caida0517-500w_10_.pcap\")\n",
    "pcap_file.append(\"caida0517-250w_10_.pcap\")\n",
    "pcap_file.append(\"caida0517-125w_10_.pcap\")\n",
    "pcap_file.append(\"caida0816-600w_10_.pcap\")\n",
    "pcap_file.append(\"caida0816-300w_10_.pcap\")\n",
    "pcap_file.append(\"caida0816-150w_10_.pcap\")\n",
    "pcap_file.append(\"zipf2a-150w_10_.pcap\") \n",
    "pcap_file.append(\"zipf2a-75w_10_.pcap\") \n",
    "pcap_file.append(\"zipf2a-35w_10_.pcap\") \n",
    "pcap_file.append(\"zipf2b-400w_10_.pcap\") \n",
    "pcap_file.append(\"zipf2b-200w_10_.pcap\") \n",
    "pcap_file.append(\"zipf2b-100w_10_.pcap\") \n",
    "pcap_file.append(\"zipf4-60w_10_.pcap\")\n",
    "pcap_file.append(\"zipf4-30w_10_.pcap\")\n",
    "pcap_file.append(\"zipf4-15w_10_.pcap\")\n",
    "\n",
    "\n",
    "# # # same dist, caida\n",
    "# for a in caida0517:\n",
    "#     for b in caida0816:\n",
    "#         for l in lens:\n",
    "#             pcap_file.append(f'{a}_{l[0]}_{b}_{l[1]}.pcap')\n",
    "# for a in caida0816:\n",
    "#     for b in caida0517:\n",
    "#         for l in lens:\n",
    "#             pcap_file.append(f'{a}_{l[0]}_{b}_{l[1]}.pcap')\n",
    "            \n",
    "# # # same dist, zipf\n",
    "# for a in zipf2a:\n",
    "#     for b in zipf2b:\n",
    "#         for l in lens:\n",
    "#             pcap_file.append(f'{a}_{l[0]}_{b}_{l[1]}.pcap')\n",
    "# for a in zipf2b:\n",
    "#     for b in zipf2a:\n",
    "#         for l in lens:\n",
    "#             pcap_file.append(f'{a}_{l[0]}_{b}_{l[1]}.pcap')\n",
    "\n",
    "# # # diff dist, caida + zipf2a\n",
    "# for a in caida0517:\n",
    "#     for b in zipf2a:\n",
    "#         for l in lens:\n",
    "#             pcap_file.append(f'{a}_{l[0]}_{b}_{l[1]}.pcap')\n",
    "# for a in caida0816:\n",
    "#     for b in zipf2a:\n",
    "#         for l in lens:\n",
    "#             pcap_file.append(f'{a}_{l[0]}_{b}_{l[1]}.pcap')\n",
    "            \n",
    "# # # # diff dist, caida + zipf2b\n",
    "# for a in caida0517:\n",
    "#     for b in zipf2b:\n",
    "#         for l in lens:\n",
    "#             pcap_file.append(f'{a}_{l[0]}_{b}_{l[1]}.pcap')\n",
    "# for a in caida0816:\n",
    "#     for b in zipf2b:\n",
    "#         for l in lens:\n",
    "#             pcap_file.append(f'{a}_{l[0]}_{b}_{l[1]}.pcap')\n",
    "            \n",
    "# # # # diff dist, caida + zipf4\n",
    "# for a in caida0517:\n",
    "#     for b in zipf4:\n",
    "#         for l in lens:\n",
    "#             pcap_file.append(f'{a}_{l[0]}_{b}_{l[1]}.pcap')\n",
    "# for a in caida0816:\n",
    "#     for b in zipf4:\n",
    "#         for l in lens:\n",
    "#             pcap_file.append(f'{a}_{l[0]}_{b}_{l[1]}.pcap')\n",
    "\n",
    "# # # diff dist, zipf2a + caida\n",
    "# for a in zipf2a:\n",
    "#     for b in caida0517:\n",
    "#         for l in lens:\n",
    "#             pcap_file.append(f'{a}_{l[0]}_{b}_{l[1]}.pcap')\n",
    "#     for b in caida0816:\n",
    "#         for l in lens:\n",
    "#             pcap_file.append(f'{a}_{l[0]}_{b}_{l[1]}.pcap')\n",
    "            \n",
    "# # # diff dist, zipf2b + caida\n",
    "# for a in zipf2b:\n",
    "#     for b in caida0517:\n",
    "#         for l in lens:\n",
    "#             pcap_file.append(f'{a}_{l[0]}_{b}_{l[1]}.pcap')\n",
    "#     for b in caida0816:\n",
    "#         for l in lens:\n",
    "#             pcap_file.append(f'{a}_{l[0]}_{b}_{l[1]}.pcap')\n",
    "            \n",
    "# # # diff dist, zipf4 + caida\n",
    "# for a in zipf4:\n",
    "#     for b in caida0517:\n",
    "#         for l in lens:\n",
    "#             pcap_file.append(f'{a}_{l[0]}_{b}_{l[1]}.pcap')\n",
    "#     for b in caida0816:\n",
    "#         for l in lens:\n",
    "#             pcap_file.append(f'{a}_{l[0]}_{b}_{l[1]}.pcap')\n",
    "\n",
    "# # # # diff dist, zipf 2a + zipf4\n",
    "# for a in zipf2a:\n",
    "#     for b in zipf4:\n",
    "#         for l in lens:\n",
    "#             pcap_file.append(f'{a}_{l[0]}_{b}_{l[1]}.pcap')\n",
    "# for a in zipf4:\n",
    "#     for b in zipf2a:\n",
    "#         for l in lens:\n",
    "#             pcap_file.append(f'{a}_{l[0]}_{b}_{l[1]}.pcap')\n",
    "            \n",
    "# # # # diff dist, zipf 2b + zipf4\n",
    "# for a in zipf2b:\n",
    "#     for b in zipf4:\n",
    "#         for l in lens:\n",
    "#             pcap_file.append(f'{a}_{l[0]}_{b}_{l[1]}.pcap')\n",
    "# for a in zipf4:\n",
    "#     for b in zipf2b:\n",
    "#         for l in lens:\n",
    "#             pcap_file.append(f'{a}_{l[0]}_{b}_{l[1]}.pcap')\n",
    "            \n",
    "            \n",
    "            \n",
    "print(pcap_file)    \n",
    "print(f'Total Pcap File Number: {len(pcap_file)}')\n",
    "# widths = [2048, 4096, 8192, 16384, 32768, 65536, 131072]\n",
    "widths = [4096]\n",
    "# widths = [1024]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_profiler_bins():\n",
    "    res = {}\n",
    "    \n",
    "    profiler_path = \"../traffic_generator/fs_dist/\"\n",
    "    profiler_fsd = []\n",
    "    for file in sorted(os.listdir(profiler_path)):\n",
    "        profiler_fsd.append(file)\n",
    "        \n",
    "    for file in profiler_fsd:\n",
    "        path = os.path.join(profiler_path, file)\n",
    "        \n",
    "        # Read file to get profilers' flow size distribution\n",
    "        fsd = {}\n",
    "        fn = 0\n",
    "        with open(path, 'r') as f:\n",
    "            for line in f:\n",
    "                fsd[int(line.strip().split()[0])] = int(line.strip().split()[1])\n",
    "                fn += int(line.strip().split()[1])\n",
    "                \n",
    "        # calcualte CDF\n",
    "        cdf = {}\n",
    "        culmulative_prob = 0.0\n",
    "        for fs, freq in sorted(fsd.items()):\n",
    "            culmulative_prob += (freq/fn)\n",
    "            cdf[fs] = culmulative_prob\n",
    "            \n",
    "        # get bins\n",
    "        bin = {}\n",
    "        idx = 0\n",
    "        for fs, prob in sorted(cdf.items()):\n",
    "            while idx < round(prob * 100):\n",
    "                bin[idx] = fs\n",
    "                idx += 1\n",
    "                \n",
    "        res[file[:-4]] = bin\n",
    "            \n",
    "    return res\n",
    "    \n",
    "# prepare_profiler_bins()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(algo='cm', row=3, width=[4096], level=1, seed=1, count=1, flowkey='srcIP', \n",
    "              epochs=['10'], datasets=['zipf2a_3_caida20180517_7.pcap'], window_size=200, dev=3, ws=20):\n",
    "    \n",
    "    # top 100\n",
    "    res_sum = {}\n",
    "    res_var = {}\n",
    "    # res_sec_var = {}\n",
    "    \n",
    "    label = []\n",
    "    answer = []\n",
    "    \n",
    "    for d in datasets:\n",
    "        for w in width:\n",
    "            name = f'{d[:-5]}_{w}'\n",
    "            res_var[name] = [None]\n",
    "            # res_sec_var[name] = [None, None]\n",
    "            \n",
    "            res_total = read_sum_data(algo, row, w, level, seed, count, flowkey, epochs, d, window_size)\n",
    "\n",
    "            label.append(name)\n",
    "            answer.append(int(d.split('_')[1]))\n",
    "            # answer.append(10)\n",
    "            \n",
    "            res_sum[name] = res_total\n",
    "            \n",
    "            for i in range(1, len(res_total)):\n",
    "                res_var[name].append(res_total[i] - res_total[i-1])\n",
    "                \n",
    "            # for i in range(2, len(res_var[name])):\n",
    "            #     res_sec_var[name].append(abs(res_var[name][i] - res_var[name][i-1]))\n",
    "            \n",
    "    # res = read_data(algo, row, width, level, seed, count, flowkey, epochs, dataset, type, window_size)\n",
    "    # print(label, len(label))\n",
    "    # print(res_sum, len(res_sum))\n",
    "    # print(res_var, len(res_var))\n",
    "    # print(res_sec_var, len(res_sec_var))\n",
    "    \n",
    "    # print(answer)\n",
    "    ignore = int(1000/window_size)\n",
    "    choose = 5\n",
    "    # dev = 3.4 # 99.90%\n",
    "    # dev = 3 # 99.90%\n",
    "    # dev = 3.719 # 99.99%\n",
    "    iqr = 1.5\n",
    "    # ws = 20\n",
    "    \n",
    "    pred3 = []\n",
    "    \n",
    "    norm_hit3 = 0\n",
    "    iqr_hit3 = 0\n",
    "    \n",
    "    hit3 = []\n",
    "    \n",
    "    for i in range(len(label)):\n",
    "        \n",
    "        var_hit, time_var, sec_var_hit, time_sec_var, val, max_time = changes_occured(res_var3[label[i]][1:], res_sec_var3[label[i]][2:], dev, ws)\n",
    "        \n",
    "        pred3.append(time_sec_var)\n",
    "           \n",
    "        print(i)\n",
    "        print(label[i])\n",
    "        print('\\tTotal Flow ')\n",
    "        # print('\\t\\t', var_max3, var_avg3, var_diff3)\n",
    "        # print('\\t\\t', max(res_sec_var3[label[i]][(1+ignore):end]), sum(res_sec_var3[label[i]][(1+ignore):end]) / len(res_sec_var3[label[i]][(1+ignore):end]), max(res_sec_var3[label[i]][(1+ignore):end]) - (sum(res_sec_var3[label[i]][(1+ignore):end]) / len(res_sec_var3[label[i]][(1+ignore):end])))\n",
    "        print('\\t\\t', res_sec_var[label[i]])\n",
    "        print(f'\\t\\tvar: {time_var}, ans: {answer[i]}, change: {var_hit}')\n",
    "        print(f'\\t\\tsec var: {time_sec_var}, ans: {answer[i]}, change: {sec_var_hit}')\n",
    "        print(f'\\t\\t{val}, max time: {max_time}')\n",
    "        print()\n",
    "        \n",
    "        if answer[i] == 10:\n",
    "            if sec_var_hit == 0:\n",
    "                hit3.append(1)\n",
    "            else:\n",
    "                hit3.append(0)\n",
    "        else:\n",
    "            if sec_var_hit == 1:\n",
    "                hit3.append(1)\n",
    "            else:\n",
    "                hit3.append(0)\n",
    "            \n",
    "        \n",
    "\n",
    "    succ3 = 0\n",
    "\n",
    "    for i in range(len(label)):\n",
    "        if hit3[i] == 1:\n",
    "            if answer[i] == 10:\n",
    "                succ3 += 1\n",
    "            else:\n",
    "                if abs(pred3[i] - answer[i]) <= 1.0:\n",
    "                    succ3 += 1\n",
    "    \n",
    "    print(\"single comprehensive predict\")\n",
    "    print(f' total flow  predict: {succ3}/{len(pred3)} {succ3*100/len(pred3)}%')\n",
    "    print()\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "        \n",
    "# predict_final_dynamic_topk(width=widths, datasets=pcap_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
