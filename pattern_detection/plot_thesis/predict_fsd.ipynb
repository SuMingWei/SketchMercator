{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import numpy as np\n",
    "import random\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import seaborn as sns\n",
    "import math\n",
    "import sys\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_single_window_fsd_data(algo='cm', row=3, width=4096, level=1, seed=1, count=1, flowkey='srcIP', \n",
    "              epochs=['10'], dataset='caida0517-125w_10_.pcap', window_size=200):\n",
    "    res = []\n",
    "    for epoch in epochs:\n",
    "        \n",
    "        path = f\"../SketchPatternQuery/{algo}/{dataset}/\"\\\n",
    "                f\"{flowkey}/row_{row}_width_{width}_level_{level}_epoch_{epoch}_count_{count}_seed_{seed}/\"\n",
    "        \n",
    "        for dir in sorted(os.listdir(path)):\n",
    "            p = os.path.join(path, dir)\n",
    "            if os.path.isdir(p): \n",
    "                window_dir = \"window_\" + str(window_size)\n",
    "                dynamic_full_path = os.path.join(path, dir, window_dir, \"single_window_randk_summation\")\n",
    "                \n",
    "                for file in sorted(os.listdir(dynamic_full_path)):  \n",
    "                    fsd_file = os.path.join(dynamic_full_path, file)\n",
    "                    fsd = {}\n",
    "                    with open(fsd_file, 'r') as f:\n",
    "                        for line in f:\n",
    "                            if int(line.strip().split()[0]) == 0:\n",
    "                                continue\n",
    "                            fsd[int(line.strip().split()[0])] = int(line.strip().split()[1])\n",
    "                            \n",
    "                    res.append(fsd)\n",
    "            \n",
    "    return res\n",
    "\n",
    "# read_fsd_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_single_window_gt_fsd_data(algo='cm', row=3, width=4096, level=1, seed=1, count=1, flowkey='srcIP', \n",
    "              epochs=['10'], dataset='caida0517-125w_10_.pcap', window_size=200):\n",
    "    res = []\n",
    "    for epoch in epochs:\n",
    "        \n",
    "        path = f\"../SketchPatternQuery/{algo}/{dataset}/\"\\\n",
    "                f\"{flowkey}/row_{row}_width_{width}_level_{level}_epoch_{epoch}_count_{count}_seed_{seed}/\"\n",
    "        \n",
    "        for dir in sorted(os.listdir(path)):\n",
    "            p = os.path.join(path, dir)\n",
    "            if os.path.isdir(p): \n",
    "                window_dir = \"window_\" + str(window_size)\n",
    "                dynamic_full_path = os.path.join(path, dir, window_dir, \"single_window_randk_gt_summation\")\n",
    "                \n",
    "                for file in sorted(os.listdir(dynamic_full_path)):  \n",
    "                    fsd_file = os.path.join(dynamic_full_path, file)\n",
    "                    fsd = {}\n",
    "                    with open(fsd_file, 'r') as f:\n",
    "                        for line in f:\n",
    "                            if int(line.strip().split()[0]) == 0:\n",
    "                                continue\n",
    "                            fsd[int(line.strip().split()[0])] = int(line.strip().split()[1])\n",
    "                            \n",
    "                    res.append(fsd)\n",
    "            \n",
    "    return res\n",
    "\n",
    "# read_fsd_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['caida0517-500w_10_.pcap', 'caida0517-250w_10_.pcap', 'caida0517-150w_10_.pcap', 'caida0517-070w_10_.pcap', 'caida0517-030w_10_.pcap', 'zipf2a-150w_10_.pcap', 'zipf2a-070w_10_.pcap', 'zipf2a-030w_10_.pcap', 'zipf10-070w_10_.pcap', 'zipf10-030w_10_.pcap', 'caida0517-500w_6_zipf2a-150w_4.pcap', 'caida0517-500w_6_zipf2a-070w_4.pcap', 'caida0517-500w_6_zipf2a-030w_4.pcap', 'caida0517-250w_6_zipf2a-150w_4.pcap', 'caida0517-250w_6_zipf2a-070w_4.pcap', 'caida0517-250w_6_zipf2a-030w_4.pcap', 'caida0517-150w_6_zipf2a-150w_4.pcap', 'caida0517-150w_6_zipf2a-070w_4.pcap', 'caida0517-150w_6_zipf2a-030w_4.pcap', 'caida0517-070w_6_zipf2a-150w_4.pcap', 'caida0517-070w_6_zipf2a-070w_4.pcap', 'caida0517-070w_6_zipf2a-030w_4.pcap', 'caida0517-030w_6_zipf2a-150w_4.pcap', 'caida0517-030w_6_zipf2a-070w_4.pcap', 'caida0517-030w_6_zipf2a-030w_4.pcap', 'zipf2a-150w_6_caida0517-500w_4.pcap', 'zipf2a-150w_6_caida0517-250w_4.pcap', 'zipf2a-150w_6_caida0517-150w_4.pcap', 'zipf2a-150w_6_caida0517-070w_4.pcap', 'zipf2a-150w_6_caida0517-030w_4.pcap', 'zipf2a-070w_6_caida0517-500w_4.pcap', 'zipf2a-070w_6_caida0517-250w_4.pcap', 'zipf2a-070w_6_caida0517-150w_4.pcap', 'zipf2a-070w_6_caida0517-070w_4.pcap', 'zipf2a-070w_6_caida0517-030w_4.pcap', 'zipf2a-030w_6_caida0517-500w_4.pcap', 'zipf2a-030w_6_caida0517-250w_4.pcap', 'zipf2a-030w_6_caida0517-150w_4.pcap', 'zipf2a-030w_6_caida0517-070w_4.pcap', 'zipf2a-030w_6_caida0517-030w_4.pcap', 'caida0517-500w_6_zipf10-070w_4.pcap', 'caida0517-500w_6_zipf10-030w_4.pcap', 'caida0517-250w_6_zipf10-070w_4.pcap', 'caida0517-250w_6_zipf10-030w_4.pcap', 'caida0517-150w_6_zipf10-070w_4.pcap', 'caida0517-150w_6_zipf10-030w_4.pcap', 'caida0517-070w_6_zipf10-070w_4.pcap', 'caida0517-070w_6_zipf10-030w_4.pcap', 'caida0517-030w_6_zipf10-070w_4.pcap', 'caida0517-030w_6_zipf10-030w_4.pcap', 'zipf10-070w_6_caida0517-500w_4.pcap', 'zipf10-070w_6_caida0517-250w_4.pcap', 'zipf10-070w_6_caida0517-150w_4.pcap', 'zipf10-070w_6_caida0517-070w_4.pcap', 'zipf10-070w_6_caida0517-030w_4.pcap', 'zipf10-030w_6_caida0517-500w_4.pcap', 'zipf10-030w_6_caida0517-250w_4.pcap', 'zipf10-030w_6_caida0517-150w_4.pcap', 'zipf10-030w_6_caida0517-070w_4.pcap', 'zipf10-030w_6_caida0517-030w_4.pcap', 'zipf2a-150w_6_zipf10-070w_4.pcap', 'zipf2a-150w_6_zipf10-030w_4.pcap', 'zipf2a-070w_6_zipf10-070w_4.pcap', 'zipf2a-070w_6_zipf10-030w_4.pcap', 'zipf2a-030w_6_zipf10-070w_4.pcap', 'zipf2a-030w_6_zipf10-030w_4.pcap', 'zipf10-070w_6_zipf2a-150w_4.pcap', 'zipf10-070w_6_zipf2a-070w_4.pcap', 'zipf10-070w_6_zipf2a-030w_4.pcap', 'zipf10-030w_6_zipf2a-150w_4.pcap', 'zipf10-030w_6_zipf2a-070w_4.pcap', 'zipf10-030w_6_zipf2a-030w_4.pcap', 'caida0517-500w_6_caida0517-250w_4.pcap', 'caida0517-500w_6_caida0517-150w_4.pcap', 'caida0517-500w_6_caida0517-070w_4.pcap', 'caida0517-500w_6_caida0517-030w_4.pcap', 'caida0517-250w_6_caida0517-500w_4.pcap', 'caida0517-250w_6_caida0517-150w_4.pcap', 'caida0517-250w_6_caida0517-070w_4.pcap', 'caida0517-250w_6_caida0517-030w_4.pcap', 'caida0517-150w_6_caida0517-500w_4.pcap', 'caida0517-150w_6_caida0517-250w_4.pcap', 'caida0517-150w_6_caida0517-070w_4.pcap', 'caida0517-150w_6_caida0517-030w_4.pcap', 'caida0517-070w_6_caida0517-500w_4.pcap', 'caida0517-070w_6_caida0517-250w_4.pcap', 'caida0517-070w_6_caida0517-150w_4.pcap', 'caida0517-070w_6_caida0517-030w_4.pcap', 'caida0517-030w_6_caida0517-500w_4.pcap', 'caida0517-030w_6_caida0517-250w_4.pcap', 'caida0517-030w_6_caida0517-150w_4.pcap', 'caida0517-030w_6_caida0517-070w_4.pcap', 'zipf2a-150w_6_zipf2a-070w_4.pcap', 'zipf2a-150w_6_zipf2a-030w_4.pcap', 'zipf2a-070w_6_zipf2a-150w_4.pcap', 'zipf2a-070w_6_zipf2a-030w_4.pcap', 'zipf2a-030w_6_zipf2a-150w_4.pcap', 'zipf2a-030w_6_zipf2a-070w_4.pcap', 'zipf10-070w_6_zipf10-030w_4.pcap', 'zipf10-030w_6_zipf10-070w_4.pcap']\n",
      "Total Pcap File Number: 100\n"
     ]
    }
   ],
   "source": [
    "## parameters\n",
    "\n",
    "caida0517 = [\"caida0517-500w\", \"caida0517-250w\", \"caida0517-150w\", \"caida0517-070w\", \"caida0517-030w\"]\n",
    "zipf2a = [\"zipf2a-150w\", \"zipf2a-070w\", \"zipf2a-030w\"]\n",
    "zipf10 = [\"zipf10-070w\", \"zipf10-030w\"]\n",
    "\n",
    "\n",
    "lens = [\n",
    "        # [\"5\", \"5\"],\n",
    "        [\"6\", \"4\"],\n",
    "        # [\"7\", \"3\"],\n",
    "        # [\"8\", \"2\"],\n",
    "        ]\n",
    "\n",
    "pcap_file = []\n",
    "    \n",
    "# # single dataset\n",
    "pcap_file.append(\"caida0517-500w_10_.pcap\")\n",
    "pcap_file.append(\"caida0517-250w_10_.pcap\")\n",
    "pcap_file.append(\"caida0517-150w_10_.pcap\")\n",
    "pcap_file.append(\"caida0517-070w_10_.pcap\")\n",
    "pcap_file.append(\"caida0517-030w_10_.pcap\")\n",
    "pcap_file.append(\"zipf2a-150w_10_.pcap\") \n",
    "pcap_file.append(\"zipf2a-070w_10_.pcap\") \n",
    "pcap_file.append(\"zipf2a-030w_10_.pcap\") \n",
    "pcap_file.append(\"zipf10-070w_10_.pcap\") \n",
    "pcap_file.append(\"zipf10-030w_10_.pcap\") \n",
    "\n",
    "### caida + zipf2a [10:25]\n",
    "for a in caida0517:\n",
    "    for b in zipf2a:\n",
    "        for l in lens:\n",
    "            pcap_file.append(f'{a}_{l[0]}_{b}_{l[1]}.pcap')\n",
    "            \n",
    "### zipf2a + caida [25:40]\n",
    "for a in zipf2a:\n",
    "    for b in caida0517:\n",
    "        for l in lens:\n",
    "            pcap_file.append(f'{a}_{l[0]}_{b}_{l[1]}.pcap')\n",
    "            \n",
    "### caida + zipf10 [40:50]\n",
    "for a in caida0517:\n",
    "    for b in zipf10:\n",
    "        for l in lens:\n",
    "            pcap_file.append(f'{a}_{l[0]}_{b}_{l[1]}.pcap')\n",
    "            \n",
    "### zipf10 + caida [50:60]\n",
    "for a in zipf10:\n",
    "    for b in caida0517:\n",
    "        for l in lens:\n",
    "            pcap_file.append(f'{a}_{l[0]}_{b}_{l[1]}.pcap')\n",
    "            \n",
    "### zipf2a + zipf10 [60:66]\n",
    "for a in zipf2a:\n",
    "    for b in zipf10:\n",
    "        for l in lens:\n",
    "            pcap_file.append(f'{a}_{l[0]}_{b}_{l[1]}.pcap')\n",
    "            \n",
    "### zipf10 + zipf2a [66:72]\n",
    "for a in zipf10:\n",
    "    for b in zipf2a:\n",
    "        for l in lens:\n",
    "            pcap_file.append(f'{a}_{l[0]}_{b}_{l[1]}.pcap')\n",
    "            \n",
    "### caida + caida [72:92]\n",
    "for a in caida0517:\n",
    "    for b in caida0517:\n",
    "        if a == b:\n",
    "            continue\n",
    "        for l in lens:\n",
    "            pcap_file.append(f'{a}_{l[0]}_{b}_{l[1]}.pcap')\n",
    "            \n",
    "### zipf2a + zipf2a [92:98]\n",
    "for a in zipf2a:\n",
    "    for b in zipf2a:\n",
    "        if a == b:\n",
    "            continue\n",
    "        for l in lens:\n",
    "            pcap_file.append(f'{a}_{l[0]}_{b}_{l[1]}.pcap')\n",
    "            \n",
    "### zipf10 + zipf10 [98:100]\n",
    "for a in zipf10:\n",
    "    for b in zipf10:\n",
    "        if a == b:\n",
    "            continue\n",
    "        for l in lens:\n",
    "            pcap_file.append(f'{a}_{l[0]}_{b}_{l[1]}.pcap')\n",
    "            \n",
    "        \n",
    "            \n",
    "print(pcap_file)    \n",
    "print(f'Total Pcap File Number: {len(pcap_file)}')\n",
    "# widths = [2048, 4096, 8192, 16384, 32768, 65536, 131072]\n",
    "widths = [4096]\n",
    "# widths = [1024]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict FSD Changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def changes_occured(sec_var, n, ws=20):\n",
    "    \n",
    "    time_sec_var = -1.0\n",
    "    \n",
    "    val = 0\n",
    "    max_time = -1.0\n",
    "    \n",
    "    # for each sliding window           \n",
    "    for i in range(len(sec_var) - ws + 1):            \n",
    "        sec_var_mean = np.mean(sec_var[0+i:ws+i])\n",
    "        sec_var_std_dev = np.std(sec_var[0+i:ws+i])\n",
    "        \n",
    "        # check by sec var outliers\n",
    "        if abs(sec_var[ws+i-1] - sec_var_mean) > (n * sec_var_std_dev):\n",
    "            if time_sec_var == -1.0:\n",
    "                time_sec_var = (4+(ws+i-1)-1)/5\n",
    "                val = sec_var[ws+i-1]\n",
    "                break\n",
    "                \n",
    "    if val == 0:\n",
    "        val = max(sec_var)\n",
    "        max_time = (4 + sec_var.index(val) - 1)/5\n",
    "        \n",
    "    sec_var_hit = 0\n",
    "    \n",
    "    if time_sec_var != -1.0:\n",
    "        sec_var_hit = 1\n",
    "    \n",
    "    return sec_var_hit, time_sec_var, val, max_time\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mrd(fsd1, fsd2):\n",
    "    MRD_nom = 0\n",
    "    MRD_denom = 0\n",
    "    for i in range(1, max(fsd1.keys())+1):\n",
    "        if i in fsd1.keys():\n",
    "            true = fsd1[i]\n",
    "        else:\n",
    "            true = 0\n",
    "            \n",
    "        if i in fsd2.keys():\n",
    "            est = fsd2[i]\n",
    "        else:\n",
    "            est = 0\n",
    "            \n",
    "        MRD_nom += abs(true - est)\n",
    "        MRD_denom += float(true + est)/2\n",
    "    MRD = MRD_nom/MRD_denom\n",
    "    \n",
    "    return MRD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_fsd(fsd):\n",
    "    fn = sum(list(fsd.values()))\n",
    "    \n",
    "    return {key: (val/fn) for key,val in fsd.items()}\n",
    "            \n",
    "    # calcualte CDF\n",
    "    cdf = {}\n",
    "    culmulative_prob = 0.0\n",
    "    for fs, freq in sorted(fsd.items()):\n",
    "        culmulative_prob += (freq/fn)\n",
    "        cdf[fs] = culmulative_prob\n",
    "        \n",
    "    # get bins\n",
    "    bin = {}\n",
    "    idx = 0\n",
    "    for fs, prob in sorted(cdf.items()):\n",
    "        while idx < round(prob * 100):\n",
    "            bin[idx] = fs\n",
    "            idx += 1\n",
    "            \n",
    "    qfsd = {}\n",
    "    idx = 0\n",
    "    for fs, freq in sorted(fsd.items()):\n",
    "        while fs > bin[idx]:\n",
    "            if idx < len(bin) - 1:\n",
    "                idx += 1\n",
    "            else:\n",
    "                break\n",
    "            \n",
    "        if bin[idx] in qfsd.keys():\n",
    "            qfsd[bin[idx]] += freq/fn\n",
    "        else:\n",
    "            qfsd[bin[idx]] = freq/fn\n",
    "             \n",
    "    return qfsd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_mrd_variation(mrd_var, name, window_size=200, typ='Var'):\n",
    "    \n",
    "    res = []\n",
    "    \n",
    "    res.append(mrd_var)\n",
    "    \n",
    "    print(name)\n",
    "    print(mrd_var)\n",
    "\n",
    "    plt.figure(figsize=(12, 4))\n",
    "        \n",
    "    for i in range(len(res)):\n",
    "        plt.plot(res[i], label=f'MRD {typ}')\n",
    "\n",
    "    # Add labels and legend\n",
    "    plt.xlabel('Time (sec)')\n",
    "    if typ == \"MRD\":\n",
    "        plt.ylabel('MRD')\n",
    "    else:\n",
    "        plt.ylabel('Value')\n",
    "    plt.title('%s MRD Variation' % (name))\n",
    "    # plt.axhline(10000, c=\"black\")\n",
    "    ticks = [i for i in range(int(10*1000/window_size) + 1)]\n",
    "    adjusted_ticks = [tick * (window_size / 1000) for tick in ticks[0::int(1000 / window_size)]]\n",
    "    plt.xticks(ticks[0::int(1000/window_size)], adjusted_ticks)\n",
    "    plt.legend(loc='upper left', ncol=math.ceil(len(res)/4))\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(algo='cm', row=3, width=[4096], level=1, seed=1, count=1, flowkey='srcIP', \n",
    "              epochs=['10'], datasets=['caida0517-125w_10_.pcap'], window_size=200, dev=3, ws=20):\n",
    "    \n",
    "    # top 100\n",
    "    res_fsd = {}\n",
    "    res_mrd = {}\n",
    "    res_mrd_var = {}\n",
    "    res_mrd_sec_var = {}\n",
    "    # res_sec_var = {}\n",
    "    \n",
    "    label = []\n",
    "    answer = []\n",
    "    \n",
    "    for d in datasets:\n",
    "        for w in width:\n",
    "            name = f'{d[:-5]}_{w}'\n",
    "            res_mrd[name] = [None, None] # 0, 1\n",
    "            res_mrd_var[name] = [None, None, None] # 0, 1, 2\n",
    "            res_mrd_sec_var[name] = [None, None, None, None] # 0, 1, 2, 3\n",
    "            \n",
    "            # fsd_total = read_fsd_data(algo, row, w, level, seed, count, flowkey, epochs, d, window_size)\n",
    "            # fsd_total = read_gt_fsd_data(algo, row, w, level, seed, count, flowkey, epochs, d, window_size)\n",
    "            fsd_total = read_single_window_fsd_data(algo, row, w, level, seed, count, flowkey, epochs, d, window_size)\n",
    "            # fsd_total = read_single_window_gt_fsd_data(algo, row, w, level, seed, count, flowkey, epochs, d, window_size)\n",
    "\n",
    "            label.append(name)\n",
    "            answer.append(int(d.split('_')[1]))\n",
    "            # answer.append(10)\n",
    "            \n",
    "            res_fsd[name] = fsd_total[:-1] # ignore last window (less than 200ms)\n",
    "            \n",
    "            for i in range(1, len(res_fsd[name])):\n",
    "                res_mrd[name].append(calculate_mrd(res_fsd[name][i-1], res_fsd[name][i]))\n",
    "                # res_mrd[name].append(calculate_mrd(normalize_fsd(res_fsd[name][i-1]), normalize_fsd(res_fsd[name][i])))\n",
    "                # print(normalize_fsd(res_fsd[name][i-1]))\n",
    "                # print(normalize_fsd(res_fsd[name][i]))\n",
    "                \n",
    "            # print(len(res_fsd[name]), len(res_mrd[name]), res_mrd[name])\n",
    "                \n",
    "            # plot_mrd_variation(res_mrd[name], d[:-5], window_size, 'MRD')\n",
    "                \n",
    "            for i in range(3, len(res_mrd[name])):\n",
    "                res_mrd_var[name].append(abs(res_mrd[name][i] - res_mrd[name][i-1]))\n",
    "                \n",
    "            # plot_mrd_variation(res_mrd_var[name], d[:-5], window_size, 'Var')\n",
    "                \n",
    "            for i in range(4, len(res_mrd_var[name])):\n",
    "                res_mrd_sec_var[name].append(abs(res_mrd_var[name][i] - res_mrd_var[name][i-1]))\n",
    "                \n",
    "            # plot_mrd_variation(res_mrd_sec_var[name], d[:-5], window_size, 'Sec Var')\n",
    "            # print(len(res_mrd_var[name]), len(res_mrd_sec_var[name]))\n",
    "\n",
    "    # # print(answer)\n",
    "    ignore = int(1000/window_size)\n",
    "    choose = 5\n",
    "    # dev = 3.4 # 99.90%\n",
    "    # dev = 3 # 99.90%\n",
    "    # dev = 3.719 # 99.99%\n",
    "    iqr = 1.5\n",
    "    \n",
    "    pred = []\n",
    "    \n",
    "    norm_hit = 0\n",
    "    iqr_hit = 0\n",
    "    \n",
    "    hit = []\n",
    "    \n",
    "    for i in range(len(label)):\n",
    "        \n",
    "        sec_var_hit, time_sec_var, val, max_time = changes_occured(res_mrd_sec_var[label[i]][4:], dev, ws)\n",
    "        \n",
    "        pred.append(time_sec_var)\n",
    "           \n",
    "        print(i)\n",
    "        print(label[i])\n",
    "        print('\\tFSD MRD ')\n",
    "        # print('\\t\\t', var_max3, var_avg3, var_diff3)\n",
    "        # print('\\t\\t', max(res_sec_var3[label[i]][(1+ignore):end]), sum(res_sec_var3[label[i]][(1+ignore):end]) / len(res_sec_var3[label[i]][(1+ignore):end]), max(res_sec_var3[label[i]][(1+ignore):end]) - (sum(res_sec_var3[label[i]][(1+ignore):end]) / len(res_sec_var3[label[i]][(1+ignore):end])))\n",
    "        print('\\t\\t', res_mrd_sec_var[label[i]])\n",
    "        print(f'\\t\\tsec var: {time_sec_var}, ans: {answer[i]}, change: {sec_var_hit}')\n",
    "        print(f'\\t\\t{val}, max time: {max_time}')\n",
    "        print()\n",
    "        \n",
    "        if answer[i] == 10:\n",
    "            if sec_var_hit == 0:\n",
    "                hit.append(1)\n",
    "            else:\n",
    "                hit.append(0)\n",
    "        else:\n",
    "            if sec_var_hit == 1:\n",
    "                hit.append(1)\n",
    "            else:\n",
    "                hit.append(0)\n",
    "            \n",
    "        \n",
    "\n",
    "    succ = 0\n",
    "\n",
    "    for i in range(len(label)):\n",
    "        if hit[i] == 1:\n",
    "            if answer[i] == 10:\n",
    "                succ += 1\n",
    "            else:\n",
    "                if abs(pred[i] - answer[i]) <= 1.0:\n",
    "                    succ += 1\n",
    "    \n",
    "    print(\"single comprehensive predict\")\n",
    "    print(f' total flow  predict: {succ}/{len(pred)} {succ*100/len(pred)}%')\n",
    "    print()\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "        \n",
    "# predict_final_dynamic_topk(width=widths, datasets=pcap_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict(width=widths, datasets=pcap_file[:10], window_size=200, dev=3.4, ws=25)\n",
    "# predict(width=widths, datasets=pcap_file[10:25], window_size=200, dev=3.4, ws=25)\n",
    "# predict(width=widths, datasets=pcap_file[25:40], window_size=200, dev=3.4, ws=25)\n",
    "# predict(width=widths, datasets=pcap_file[40:50], window_size=200, dev=3.4, ws=25)\n",
    "# predict(width=widths, datasets=pcap_file[50:60], window_size=200, dev=3.4, ws=25)\n",
    "# predict(width=widths, datasets=pcap_file[60:66], window_size=200, dev=3.4, ws=25)\n",
    "# predict(width=widths, datasets=pcap_file[66:72], window_size=200, dev=3.4, ws=25)\n",
    "\n",
    "# predict(width=widths, datasets=pcap_file[72:92], window_size=200, dev=3.4, ws=25)\n",
    "# predict(width=widths, datasets=pcap_file[92:98], window_size=200, dev=3.4, ws=25)\n",
    "# predict(width=widths, datasets=pcap_file[98:100], window_size=200, dev=3.4, ws=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict Current FSD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_profiler_dirty_fsd_data(algo='cm', row=3, width=4096, level=1, seed=1, count=1, flowkey='srcIP', \n",
    "              epochs=['10'], dataset='caida0517-125w_10_.pcap', window_size=200):\n",
    "    \n",
    "    profiler_fsd = {}\n",
    "    profiler_folder_path = \"/home/ming/SketchMercator/pattern_detection/traffic_generator/pcap_file_new/\"\n",
    "    for file_name in sorted(os.listdir(profiler_folder_path)):\n",
    "        profiler_fsd[file_name[:-9]] = []\n",
    "    \n",
    "    # res = {}\n",
    "    for epoch in epochs:\n",
    "        for pf in profiler_fsd.keys():\n",
    "            path = f\"../SketchPatternQueryOfflineNew/{algo}/{pf}_10_.pcap/\"\\\n",
    "                    f\"{flowkey}/row_{row}_width_{width}_level_{level}_epoch_{epoch}_count_{count}_seed_{seed}/\"\n",
    "            \n",
    "            for dir in sorted(os.listdir(path)):\n",
    "                p = os.path.join(path, dir)\n",
    "                if os.path.isdir(p): \n",
    "                    window_dir = \"window_\" + str(window_size)\n",
    "                    dynamic_full_path = os.path.join(path, dir, window_dir, \"single_window_randk_summation\")\n",
    "                    \n",
    "                    for file in sorted(os.listdir(dynamic_full_path)):  \n",
    "                        fsd_file = os.path.join(dynamic_full_path, file)\n",
    "                        fsd = {}\n",
    "                        with open(fsd_file, 'r') as f:\n",
    "                            for line in f:\n",
    "                                if int(line.strip().split()[0]) == 0:\n",
    "                                    continue\n",
    "                                fsd[int(line.strip().split()[0])] = int(line.strip().split()[1])\n",
    "                                \n",
    "                        profiler_fsd[pf].append(fsd)\n",
    "                \n",
    "    return profiler_fsd\n",
    "\n",
    "# read_fsd_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_avg_fsd(fsd_list):\n",
    "    avg_fsd = {}\n",
    "    \n",
    "    all_keys = set().union(*[d.keys() for d in fsd_list])\n",
    "    for key in all_keys:\n",
    "        avg_fsd[key] = 0\n",
    "        \n",
    "    for fsd in fsd_list:\n",
    "        for key, val in fsd.items():\n",
    "            avg_fsd[key] += val\n",
    "            \n",
    "    avg_fsd = {key: int(val/len(fsd_list)) for key, val in avg_fsd.items()}\n",
    "    \n",
    "    return avg_fsd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_dist_by_dirty_fsd(profiler_fsd, unknown_fsd):\n",
    "    \n",
    "    all_mrd = {}\n",
    "    min_mrd = sys.float_info.max\n",
    "    predict_dist = \"\"\n",
    "    for name, dist in profiler_fsd.items():\n",
    "        # mrd = calculate_mrd(dist, unknown_fsd)\n",
    "        mrd = calculate_mrd(normalize_fsd(dist), normalize_fsd(unknown_fsd))\n",
    "        all_mrd[name] = mrd\n",
    "        if mrd < min_mrd:\n",
    "            min_mrd = mrd\n",
    "            predict_dist = name\n",
    "    \n",
    "    mrds = []\n",
    "    for name, mrd in all_mrd.items():\n",
    "        mrds.append(mrd)\n",
    "        \n",
    "    # print(predict_dist, all_mrd)\n",
    "    \n",
    "    # print(len(mrds))\n",
    "    # return predict_dist, profiler_fsd[predict_dist]\n",
    "    return predict_dist, mrds\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_dist_by_dirty_fsd(algo='cm', row=3, width=[4096], level=1, seed=1, count=1, flowkey='srcIP', \n",
    "              epochs=['10'], datasets=['caida0517-125w_10_.pcap'], window_size=200, dev=3, ws=20, start=0, predict_time = 3):\n",
    "    \n",
    "    # top 10000\n",
    "    res_fsd = {}\n",
    "    \n",
    "    label = []\n",
    "    answer = []\n",
    "    \n",
    "    for d in datasets:\n",
    "        for w in width:\n",
    "            name = f'{d[:-5]}_{w}'\n",
    "            \n",
    "            # fsd_total = read_fsd_data(algo, row, w, level, seed, count, flowkey, epochs, d, window_size)\n",
    "            fsd_total = read_single_window_fsd_data(algo, row, w, level, seed, count, flowkey, epochs, d, window_size)\n",
    "            # fsd_total = read_gt_fsd_data(algo, row, w, level, seed, count, flowkey, epochs, d, window_size)\n",
    "\n",
    "            label.append(name)\n",
    "            answer.append(int(d.split('_')[1]))\n",
    "            # answer.append(10)\n",
    "            \n",
    "            res_fsd[name] = fsd_total\n",
    "            \n",
    "    \n",
    "    # find dist\n",
    "    success = 0\n",
    "    profiler_fsd = prepare_profiler_dirty_fsd_data()\n",
    "    # prepare profiler avg dirty fsd\n",
    "    profiler_avg_fsd = {}\n",
    "    for name, fsd_list in profiler_fsd.items():\n",
    "        profiler_avg_fsd[name] = get_avg_fsd(fsd_list)\n",
    "        \n",
    "    for i in range(len(label)):\n",
    "        pcap_file_name = label[i][:-5] + \".pcap\"\n",
    "        # print(len(sampled_flowkey))\n",
    "        print(\"now finding \", pcap_file_name, \"'s distribution\")\n",
    "        vote = {}\n",
    "        all_mrds = []\n",
    "        \n",
    "        ### avg\n",
    "        # selected_fsd = res_fsd[label[i]][start:min(start+int(predict_time * 1000 / window_size), len(res_fsd[label[i]]))]\n",
    "        # avg_selected_fsd = get_avg_fsd(selected_fsd)\n",
    "        # dist_name, mrds = find_dist_by_dirty_fsd(profiler_avg_fsd, avg_selected_fsd)\n",
    "        # vote[dist_name] = 1\n",
    "        \n",
    "        ### vote\n",
    "        for j in range(min(int(predict_time * 1000 / window_size), len(res_fsd[label[i]])-start)):\n",
    "            # print(start + j)\n",
    "            dist_name, mrds = find_dist_by_dirty_fsd(profiler_avg_fsd, res_fsd[label[i]][start+j])\n",
    "            all_mrds.append(mrds)\n",
    "            # break\n",
    "            # print(dist_name)\n",
    "            if dist_name in vote:\n",
    "                vote[dist_name] += 1\n",
    "            else:\n",
    "                vote[dist_name] = 1\n",
    "        \n",
    "        if start == 0 or start == 5:\n",
    "            if pcap_file_name.split(\"_\")[0] == max(vote, key=vote.get).split(\"_\")[0]:\n",
    "                success += 1\n",
    "            else:\n",
    "                if pcap_file_name.split(\"-\")[0] == max(vote, key=vote.get).split(\"-\")[0]:\n",
    "                    success += 1\n",
    "        else:\n",
    "            if pcap_file_name.split(\"_\")[2] == max(vote, key=vote.get).split(\"_\")[0]:\n",
    "                success += 1\n",
    "            else:\n",
    "                if pcap_file_name.split(\"-\")[1].split(\"_\")[-1] == max(vote, key=vote.get).split(\"-\")[0]:\n",
    "                    success += 1\n",
    "        \n",
    "        print(\"==> \", max(vote, key=vote.get), vote)\n",
    "        # plot_mrd(pcap_file_name[:-5], all_mrds, window_size, predict_time, pcap_file_name.split(\"_\")[0])\n",
    "        print(\"---\\n\")\n",
    "        \n",
    "    \n",
    "    print(f\"predict : {success}/{len(label)} , ({success*100/len(label)} %)\")\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now finding  caida0517-500w_10_.pcap 's distribution\n",
      "==>  caida0517-500w {'caida0517-500w': 10}\n",
      "---\n",
      "\n",
      "now finding  caida0517-250w_10_.pcap 's distribution\n",
      "==>  caida0517-250w {'caida0517-250w': 10}\n",
      "---\n",
      "\n",
      "now finding  caida0517-150w_10_.pcap 's distribution\n",
      "==>  caida0517-150w {'caida0517-150w': 9, 'caida0517-250w': 1}\n",
      "---\n",
      "\n",
      "now finding  caida0517-070w_10_.pcap 's distribution\n",
      "==>  caida0517-070w {'caida0517-030w': 1, 'caida0517-070w': 9}\n",
      "---\n",
      "\n",
      "now finding  caida0517-030w_10_.pcap 's distribution\n",
      "==>  caida0517-030w {'caida0517-030w': 9, 'caida0517-070w': 1}\n",
      "---\n",
      "\n",
      "now finding  zipf2a-150w_10_.pcap 's distribution\n",
      "==>  zipf2a-150w {'caida0517-070w': 1, 'caida0517-150w': 1, 'zipf2a-150w': 8}\n",
      "---\n",
      "\n",
      "now finding  zipf2a-070w_10_.pcap 's distribution\n",
      "==>  zipf2a-070w {'zipf2a-070w': 8, 'caida0517-030w': 1, 'zipf2a-150w': 1}\n",
      "---\n",
      "\n",
      "now finding  zipf2a-030w_10_.pcap 's distribution\n",
      "==>  zipf2a-070w {'zipf2a-070w': 5, 'zipf2a-030w': 5}\n",
      "---\n",
      "\n",
      "now finding  zipf10-070w_10_.pcap 's distribution\n",
      "==>  zipf10-070w {'zipf10-070w': 10}\n",
      "---\n",
      "\n",
      "now finding  zipf10-030w_10_.pcap 's distribution\n",
      "==>  zipf10-070w {'zipf10-070w': 8, 'zipf10-030w': 2}\n",
      "---\n",
      "\n",
      "predict : 10/10 , (100.0 %)\n",
      "now finding  caida0517-500w_6_caida0517-250w_4.pcap 's distribution\n",
      "==>  caida0517-250w {'caida0517-070w': 1, 'caida0517-250w': 9}\n",
      "---\n",
      "\n",
      "now finding  caida0517-500w_6_caida0517-150w_4.pcap 's distribution\n",
      "==>  caida0517-150w {'caida0517-070w': 1, 'caida0517-250w': 1, 'caida0517-150w': 8}\n",
      "---\n",
      "\n",
      "now finding  caida0517-500w_6_caida0517-070w_4.pcap 's distribution\n",
      "==>  caida0517-070w {'zipf2a-150w': 1, 'caida0517-150w': 3, 'caida0517-070w': 6}\n",
      "---\n",
      "\n",
      "now finding  caida0517-500w_6_caida0517-030w_4.pcap 's distribution\n",
      "==>  caida0517-070w {'zipf2a-070w': 1, 'caida0517-070w': 6, 'caida0517-030w': 3}\n",
      "---\n",
      "\n",
      "now finding  caida0517-250w_6_caida0517-500w_4.pcap 's distribution\n",
      "==>  caida0517-500w {'caida0517-250w': 1, 'caida0517-500w': 9}\n",
      "---\n",
      "\n",
      "now finding  caida0517-250w_6_caida0517-150w_4.pcap 's distribution\n",
      "==>  caida0517-150w {'caida0517-070w': 1, 'caida0517-250w': 3, 'caida0517-150w': 6}\n",
      "---\n",
      "\n",
      "now finding  caida0517-250w_6_caida0517-070w_4.pcap 's distribution\n",
      "==>  caida0517-070w {'caida0517-070w': 7, 'caida0517-150w': 3}\n",
      "---\n",
      "\n",
      "now finding  caida0517-250w_6_caida0517-030w_4.pcap 's distribution\n",
      "==>  caida0517-070w {'caida0517-070w': 6, 'caida0517-030w': 4}\n",
      "---\n",
      "\n",
      "now finding  caida0517-150w_6_caida0517-500w_4.pcap 's distribution\n",
      "==>  caida0517-500w {'caida0517-250w': 1, 'caida0517-500w': 9}\n",
      "---\n",
      "\n",
      "now finding  caida0517-150w_6_caida0517-250w_4.pcap 's distribution\n",
      "==>  caida0517-250w {'caida0517-150w': 1, 'caida0517-250w': 9}\n",
      "---\n",
      "\n",
      "now finding  caida0517-150w_6_caida0517-070w_4.pcap 's distribution\n",
      "==>  caida0517-070w {'zipf2a-150w': 1, 'caida0517-150w': 3, 'caida0517-070w': 6}\n",
      "---\n",
      "\n",
      "now finding  caida0517-150w_6_caida0517-030w_4.pcap 's distribution\n",
      "==>  caida0517-070w {'caida0517-070w': 6, 'caida0517-150w': 1, 'caida0517-030w': 2, 'zipf2a-150w': 1}\n",
      "---\n",
      "\n",
      "now finding  caida0517-070w_6_caida0517-500w_4.pcap 's distribution\n",
      "==>  caida0517-500w {'caida0517-250w': 1, 'caida0517-500w': 9}\n",
      "---\n",
      "\n",
      "now finding  caida0517-070w_6_caida0517-250w_4.pcap 's distribution\n",
      "==>  caida0517-250w {'caida0517-070w': 1, 'caida0517-250w': 9}\n",
      "---\n",
      "\n",
      "now finding  caida0517-070w_6_caida0517-150w_4.pcap 's distribution\n",
      "==>  caida0517-150w {'caida0517-070w': 1, 'caida0517-250w': 1, 'caida0517-150w': 8}\n",
      "---\n",
      "\n",
      "now finding  caida0517-070w_6_caida0517-030w_4.pcap 's distribution\n",
      "==>  caida0517-030w {'zipf2a-070w': 1, 'caida0517-070w': 3, 'caida0517-030w': 6}\n",
      "---\n",
      "\n",
      "now finding  caida0517-030w_6_caida0517-500w_4.pcap 's distribution\n",
      "==>  caida0517-500w {'caida0517-250w': 1, 'caida0517-500w': 9}\n",
      "---\n",
      "\n",
      "now finding  caida0517-030w_6_caida0517-250w_4.pcap 's distribution\n",
      "==>  caida0517-250w {'caida0517-150w': 1, 'caida0517-250w': 9}\n",
      "---\n",
      "\n",
      "now finding  caida0517-030w_6_caida0517-150w_4.pcap 's distribution\n",
      "==>  caida0517-150w {'caida0517-070w': 1, 'caida0517-150w': 9}\n",
      "---\n",
      "\n",
      "now finding  caida0517-030w_6_caida0517-070w_4.pcap 's distribution\n",
      "==>  caida0517-070w {'caida0517-070w': 10}\n",
      "---\n",
      "\n",
      "predict : 20/20 , (100.0 %)\n",
      "now finding  zipf2a-150w_6_zipf2a-070w_4.pcap 's distribution\n",
      "==>  zipf2a-070w {'zipf2a-070w': 9, 'zipf2a-030w': 1}\n",
      "---\n",
      "\n",
      "now finding  zipf2a-150w_6_zipf2a-030w_4.pcap 's distribution\n",
      "==>  zipf2a-030w {'zipf2a-070w': 1, 'zipf2a-030w': 9}\n",
      "---\n",
      "\n",
      "now finding  zipf2a-070w_6_zipf2a-150w_4.pcap 's distribution\n",
      "==>  zipf2a-150w {'caida0517-070w': 2, 'zipf2a-150w': 8}\n",
      "---\n",
      "\n",
      "now finding  zipf2a-070w_6_zipf2a-030w_4.pcap 's distribution\n",
      "==>  zipf2a-030w {'zipf2a-030w': 10}\n",
      "---\n",
      "\n",
      "now finding  zipf2a-030w_6_zipf2a-150w_4.pcap 's distribution\n",
      "==>  zipf2a-150w {'caida0517-150w': 1, 'caida0517-070w': 1, 'zipf2a-150w': 8}\n",
      "---\n",
      "\n",
      "now finding  zipf2a-030w_6_zipf2a-070w_4.pcap 's distribution\n",
      "==>  zipf2a-070w {'zipf2a-150w': 1, 'zipf2a-070w': 9}\n",
      "---\n",
      "\n",
      "predict : 6/6 , (100.0 %)\n",
      "now finding  zipf10-070w_6_zipf10-030w_4.pcap 's distribution\n",
      "==>  zipf10-070w {'zipf10-070w': 7, 'zipf10-030w': 3}\n",
      "---\n",
      "\n",
      "now finding  zipf10-030w_6_zipf10-070w_4.pcap 's distribution\n",
      "==>  zipf10-070w {'zipf10-070w': 10}\n",
      "---\n",
      "\n",
      "predict : 2/2 , (100.0 %)\n",
      "now finding  caida0517-500w_6_zipf2a-150w_4.pcap 's distribution\n",
      "==>  caida0517-150w {'caida0517-150w': 10}\n",
      "---\n",
      "\n",
      "now finding  caida0517-500w_6_zipf2a-070w_4.pcap 's distribution\n",
      "==>  caida0517-030w {'caida0517-030w': 5, 'caida0517-070w': 4, 'zipf2a-150w': 1}\n",
      "---\n",
      "\n",
      "now finding  caida0517-500w_6_zipf2a-030w_4.pcap 's distribution\n",
      "==>  zipf2a-070w {'zipf2a-070w': 8, 'caida0517-030w': 1, 'zipf2a-150w': 1}\n",
      "---\n",
      "\n",
      "now finding  caida0517-250w_6_zipf2a-150w_4.pcap 's distribution\n",
      "==>  caida0517-150w {'caida0517-150w': 9, 'caida0517-070w': 1}\n",
      "---\n",
      "\n",
      "now finding  caida0517-250w_6_zipf2a-070w_4.pcap 's distribution\n",
      "==>  zipf2a-150w {'caida0517-070w': 2, 'caida0517-030w': 3, 'zipf2a-150w': 5}\n",
      "---\n",
      "\n",
      "now finding  caida0517-250w_6_zipf2a-030w_4.pcap 's distribution\n",
      "==>  zipf2a-070w {'zipf2a-070w': 10}\n",
      "---\n",
      "\n",
      "now finding  caida0517-150w_6_zipf2a-150w_4.pcap 's distribution\n",
      "==>  caida0517-150w {'caida0517-150w': 7, 'caida0517-070w': 3}\n",
      "---\n",
      "\n",
      "now finding  caida0517-150w_6_zipf2a-070w_4.pcap 's distribution\n",
      "==>  zipf2a-150w {'caida0517-070w': 4, 'zipf2a-150w': 5, 'zipf2a-070w': 1}\n",
      "---\n",
      "\n",
      "now finding  caida0517-150w_6_zipf2a-030w_4.pcap 's distribution\n",
      "==>  zipf2a-070w {'zipf2a-070w': 10}\n",
      "---\n",
      "\n",
      "now finding  caida0517-070w_6_zipf2a-150w_4.pcap 's distribution\n",
      "==>  caida0517-070w {'caida0517-150w': 3, 'caida0517-070w': 6, 'zipf2a-150w': 1}\n",
      "---\n",
      "\n",
      "now finding  caida0517-070w_6_zipf2a-070w_4.pcap 's distribution\n",
      "==>  zipf2a-150w {'zipf2a-150w': 6, 'zipf2a-070w': 4}\n",
      "---\n",
      "\n",
      "now finding  caida0517-070w_6_zipf2a-030w_4.pcap 's distribution\n",
      "==>  zipf2a-070w {'zipf2a-070w': 10}\n",
      "---\n",
      "\n",
      "now finding  caida0517-030w_6_zipf2a-150w_4.pcap 's distribution\n",
      "==>  zipf2a-150w {'caida0517-070w': 3, 'zipf2a-150w': 7}\n",
      "---\n",
      "\n",
      "now finding  caida0517-030w_6_zipf2a-070w_4.pcap 's distribution\n",
      "==>  zipf2a-070w {'zipf2a-150w': 2, 'zipf2a-070w': 8}\n",
      "---\n",
      "\n",
      "now finding  caida0517-030w_6_zipf2a-030w_4.pcap 's distribution\n",
      "==>  zipf2a-070w {'zipf2a-070w': 7, 'zipf2a-030w': 3}\n",
      "---\n",
      "\n",
      "predict : 10/15 , (66.66666666666667 %)\n",
      "now finding  zipf2a-150w_6_caida0517-500w_4.pcap 's distribution\n",
      "==>  caida0517-500w {'caida0517-500w': 10}\n",
      "---\n",
      "\n",
      "now finding  zipf2a-150w_6_caida0517-250w_4.pcap 's distribution\n",
      "==>  caida0517-250w {'zipf10-030w': 2, 'caida0517-250w': 8}\n",
      "---\n",
      "\n",
      "now finding  zipf2a-150w_6_caida0517-150w_4.pcap 's distribution\n",
      "==>  caida0517-150w {'caida0517-250w': 3, 'caida0517-150w': 7}\n",
      "---\n",
      "\n",
      "now finding  zipf2a-150w_6_caida0517-070w_4.pcap 's distribution\n",
      "==>  caida0517-070w {'caida0517-150w': 3, 'caida0517-070w': 7}\n",
      "---\n",
      "\n",
      "now finding  zipf2a-150w_6_caida0517-030w_4.pcap 's distribution\n",
      "==>  caida0517-070w {'caida0517-150w': 1, 'caida0517-070w': 7, 'zipf2a-150w': 2}\n",
      "---\n",
      "\n",
      "now finding  zipf2a-070w_6_caida0517-500w_4.pcap 's distribution\n",
      "==>  caida0517-500w {'caida0517-500w': 10}\n",
      "---\n",
      "\n",
      "now finding  zipf2a-070w_6_caida0517-250w_4.pcap 's distribution\n",
      "==>  caida0517-250w {'caida0517-500w': 1, 'caida0517-250w': 9}\n",
      "---\n",
      "\n",
      "now finding  zipf2a-070w_6_caida0517-150w_4.pcap 's distribution\n",
      "==>  caida0517-150w {'caida0517-250w': 2, 'caida0517-150w': 8}\n",
      "---\n",
      "\n",
      "now finding  zipf2a-070w_6_caida0517-070w_4.pcap 's distribution\n",
      "==>  caida0517-070w {'caida0517-150w': 2, 'zipf2a-150w': 1, 'caida0517-070w': 7}\n",
      "---\n",
      "\n",
      "now finding  zipf2a-070w_6_caida0517-030w_4.pcap 's distribution\n",
      "==>  zipf2a-150w {'caida0517-150w': 1, 'caida0517-070w': 2, 'zipf2a-150w': 6, 'caida0517-030w': 1}\n",
      "---\n",
      "\n",
      "now finding  zipf2a-030w_6_caida0517-500w_4.pcap 's distribution\n",
      "==>  caida0517-500w {'caida0517-500w': 10}\n",
      "---\n",
      "\n",
      "now finding  zipf2a-030w_6_caida0517-250w_4.pcap 's distribution\n",
      "==>  caida0517-250w {'caida0517-500w': 1, 'caida0517-250w': 8, 'caida0517-150w': 1}\n",
      "---\n",
      "\n",
      "now finding  zipf2a-030w_6_caida0517-150w_4.pcap 's distribution\n",
      "==>  caida0517-150w {'caida0517-250w': 2, 'caida0517-150w': 8}\n",
      "---\n",
      "\n",
      "now finding  zipf2a-030w_6_caida0517-070w_4.pcap 's distribution\n",
      "==>  caida0517-070w {'caida0517-150w': 1, 'caida0517-070w': 9}\n",
      "---\n",
      "\n",
      "now finding  zipf2a-030w_6_caida0517-030w_4.pcap 's distribution\n",
      "==>  zipf2a-150w {'caida0517-070w': 3, 'zipf2a-150w': 6, 'zipf2a-070w': 1}\n",
      "---\n",
      "\n",
      "predict : 13/15 , (86.66666666666667 %)\n",
      "now finding  caida0517-500w_6_zipf10-070w_4.pcap 's distribution\n",
      "==>  zipf10-070w {'zipf10-070w': 6, 'zipf10-030w': 4}\n",
      "---\n",
      "\n",
      "now finding  caida0517-500w_6_zipf10-030w_4.pcap 's distribution\n",
      "==>  zipf10-030w {'zipf10-030w': 7, 'caida0517-250w': 2, 'zipf10-070w': 1}\n",
      "---\n",
      "\n",
      "now finding  caida0517-250w_6_zipf10-070w_4.pcap 's distribution\n",
      "==>  zipf10-030w {'zipf10-070w': 2, 'zipf10-030w': 6, 'caida0517-250w': 2}\n",
      "---\n",
      "\n",
      "now finding  caida0517-250w_6_zipf10-030w_4.pcap 's distribution\n",
      "==>  zipf10-030w {'zipf10-030w': 6, 'caida0517-250w': 4}\n",
      "---\n",
      "\n",
      "now finding  caida0517-150w_6_zipf10-070w_4.pcap 's distribution\n",
      "==>  zipf10-030w {'zipf10-030w': 5, 'caida0517-250w': 5}\n",
      "---\n",
      "\n",
      "now finding  caida0517-150w_6_zipf10-030w_4.pcap 's distribution\n",
      "==>  caida0517-250w {'zipf10-030w': 1, 'caida0517-250w': 9}\n",
      "---\n",
      "\n",
      "now finding  caida0517-070w_6_zipf10-070w_4.pcap 's distribution\n",
      "==>  zipf10-030w {'zipf10-070w': 2, 'zipf10-030w': 7, 'caida0517-250w': 1}\n",
      "---\n",
      "\n",
      "now finding  caida0517-070w_6_zipf10-030w_4.pcap 's distribution\n",
      "==>  caida0517-250w {'caida0517-250w': 7, 'zipf10-030w': 3}\n",
      "---\n",
      "\n",
      "now finding  caida0517-030w_6_zipf10-070w_4.pcap 's distribution\n",
      "==>  zipf10-070w {'zipf10-070w': 5, 'zipf10-030w': 5}\n",
      "---\n",
      "\n",
      "now finding  caida0517-030w_6_zipf10-030w_4.pcap 's distribution\n",
      "==>  zipf10-030w {'zipf10-030w': 9, 'zipf10-070w': 1}\n",
      "---\n",
      "\n",
      "predict : 8/10 , (80.0 %)\n",
      "now finding  zipf10-070w_6_caida0517-500w_4.pcap 's distribution\n",
      "==>  caida0517-500w {'caida0517-500w': 10}\n",
      "---\n",
      "\n",
      "now finding  zipf10-070w_6_caida0517-250w_4.pcap 's distribution\n",
      "==>  caida0517-250w {'zipf10-030w': 2, 'caida0517-250w': 8}\n",
      "---\n",
      "\n",
      "now finding  zipf10-070w_6_caida0517-150w_4.pcap 's distribution\n",
      "==>  caida0517-250w {'caida0517-250w': 8, 'caida0517-150w': 2}\n",
      "---\n",
      "\n",
      "now finding  zipf10-070w_6_caida0517-070w_4.pcap 's distribution\n",
      "==>  caida0517-150w {'caida0517-150w': 5, 'caida0517-070w': 5}\n",
      "---\n",
      "\n",
      "now finding  zipf10-070w_6_caida0517-030w_4.pcap 's distribution\n",
      "==>  caida0517-030w {'caida0517-150w': 2, 'caida0517-070w': 3, 'caida0517-030w': 5}\n",
      "---\n",
      "\n",
      "now finding  zipf10-030w_6_caida0517-500w_4.pcap 's distribution\n",
      "==>  caida0517-500w {'caida0517-500w': 10}\n",
      "---\n",
      "\n",
      "now finding  zipf10-030w_6_caida0517-250w_4.pcap 's distribution\n",
      "==>  caida0517-250w {'caida0517-250w': 10}\n",
      "---\n",
      "\n",
      "now finding  zipf10-030w_6_caida0517-150w_4.pcap 's distribution\n",
      "==>  caida0517-150w {'caida0517-250w': 4, 'caida0517-150w': 6}\n",
      "---\n",
      "\n",
      "now finding  zipf10-030w_6_caida0517-070w_4.pcap 's distribution\n",
      "==>  caida0517-070w {'caida0517-150w': 1, 'caida0517-070w': 9}\n",
      "---\n",
      "\n",
      "now finding  zipf10-030w_6_caida0517-030w_4.pcap 's distribution\n",
      "==>  caida0517-030w {'caida0517-030w': 8, 'caida0517-070w': 2}\n",
      "---\n",
      "\n",
      "predict : 10/10 , (100.0 %)\n",
      "now finding  zipf2a-150w_6_zipf10-070w_4.pcap 's distribution\n",
      "==>  caida0517-250w {'zipf10-030w': 4, 'caida0517-250w': 5, 'caida0517-150w': 1}\n",
      "---\n",
      "\n",
      "now finding  zipf2a-150w_6_zipf10-030w_4.pcap 's distribution\n",
      "==>  caida0517-250w {'zipf10-030w': 1, 'caida0517-250w': 7, 'caida0517-150w': 2}\n",
      "---\n",
      "\n",
      "now finding  zipf2a-070w_6_zipf10-070w_4.pcap 's distribution\n",
      "==>  caida0517-250w {'zipf10-030w': 1, 'caida0517-250w': 5, 'caida0517-150w': 4}\n",
      "---\n",
      "\n",
      "now finding  zipf2a-070w_6_zipf10-030w_4.pcap 's distribution\n",
      "==>  caida0517-150w {'caida0517-250w': 3, 'caida0517-150w': 7}\n",
      "---\n",
      "\n",
      "now finding  zipf2a-030w_6_zipf10-070w_4.pcap 's distribution\n",
      "==>  caida0517-250w {'caida0517-250w': 5, 'caida0517-150w': 1, 'zipf10-030w': 4}\n",
      "---\n",
      "\n",
      "now finding  zipf2a-030w_6_zipf10-030w_4.pcap 's distribution\n",
      "==>  caida0517-250w {'caida0517-250w': 5, 'caida0517-150w': 4, 'zipf10-030w': 1}\n",
      "---\n",
      "\n",
      "predict : 0/6 , (0.0 %)\n",
      "now finding  zipf10-070w_6_zipf2a-150w_4.pcap 's distribution\n",
      "==>  caida0517-070w {'caida0517-150w': 4, 'caida0517-070w': 6}\n",
      "---\n",
      "\n",
      "now finding  zipf10-070w_6_zipf2a-070w_4.pcap 's distribution\n",
      "==>  zipf2a-150w {'caida0517-070w': 2, 'caida0517-030w': 1, 'zipf2a-150w': 5, 'zipf2a-070w': 2}\n",
      "---\n",
      "\n",
      "now finding  zipf10-070w_6_zipf2a-030w_4.pcap 's distribution\n",
      "==>  zipf2a-070w {'caida0517-030w': 2, 'zipf2a-070w': 8}\n",
      "---\n",
      "\n",
      "now finding  zipf10-030w_6_zipf2a-150w_4.pcap 's distribution\n",
      "==>  caida0517-070w {'caida0517-150w': 2, 'caida0517-070w': 4, 'zipf2a-150w': 4}\n",
      "---\n",
      "\n",
      "now finding  zipf10-030w_6_zipf2a-070w_4.pcap 's distribution\n",
      "==>  zipf2a-070w {'caida0517-030w': 2, 'zipf2a-150w': 2, 'zipf2a-070w': 6}\n",
      "---\n",
      "\n",
      "now finding  zipf10-030w_6_zipf2a-030w_4.pcap 's distribution\n",
      "==>  zipf2a-070w {'zipf2a-070w': 8, 'zipf2a-030w': 2}\n",
      "---\n",
      "\n",
      "predict : 4/6 , (66.66666666666667 %)\n"
     ]
    }
   ],
   "source": [
    "predict_dist_by_dirty_fsd(width=widths, datasets=pcap_file[:10], window_size=200, dev=3, ws=25, start=0, predict_time = 2)\n",
    "\n",
    "predict_dist_by_dirty_fsd(width=widths, datasets=pcap_file[72:92], window_size=200, dev=3, ws=25,start=30, predict_time = 2)\n",
    "predict_dist_by_dirty_fsd(width=widths, datasets=pcap_file[92:98], window_size=200, dev=3, ws=25,start=30, predict_time = 2)\n",
    "predict_dist_by_dirty_fsd(width=widths, datasets=pcap_file[98:100], window_size=200, dev=3, ws=25,start=30, predict_time = 2)\n",
    "\n",
    "predict_dist_by_dirty_fsd(width=widths, datasets=pcap_file[10:25], window_size=200, dev=3, ws=25,start=30, predict_time = 2)\n",
    "predict_dist_by_dirty_fsd(width=widths, datasets=pcap_file[25:40], window_size=200, dev=3, ws=25,start=30, predict_time = 2)\n",
    "predict_dist_by_dirty_fsd(width=widths, datasets=pcap_file[40:50], window_size=200, dev=3, ws=25,start=30, predict_time = 2)\n",
    "predict_dist_by_dirty_fsd(width=widths, datasets=pcap_file[50:60], window_size=200, dev=3, ws=25,start=30, predict_time = 2)\n",
    "predict_dist_by_dirty_fsd(width=widths, datasets=pcap_file[60:66], window_size=200, dev=3, ws=25,start=30, predict_time = 2)\n",
    "predict_dist_by_dirty_fsd(width=widths, datasets=pcap_file[66:72], window_size=200, dev=3, ws=25,start=30, predict_time = 2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
